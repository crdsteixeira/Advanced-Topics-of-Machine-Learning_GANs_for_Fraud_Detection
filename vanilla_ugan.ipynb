{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Body>   \n",
    "<img src=\"data:image/png;base64,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\" width=\"200\" align=\"right\" >   \n",
    "<h1> <b>Advanced Topics on Machine Learning </b> </h1>\n",
    "<p><b>CÃ¡tia Teixeira</b> (200808037) | <b>Henrique Bastos</b> (202204383) | <b>Ian Karkles</b> (202200596) | <b>Vitor Pereira</b> (202210497)\n",
    "<p>Master in Data Science and Engineering</p>\n",
    "</Body>\n",
    "Faculdade de Engenharia da Universidade do Porto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation using cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/henriqueribeiro/Downloads/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(Dataset):\n",
    " \n",
    "  def __init__(self, path, fraud = True):\n",
    "    scaler = StandardScaler()\n",
    "    df = pd.read_csv(path)\n",
    "    if fraud:\n",
    "      df = df[df['Class'] == 1]\n",
    " \n",
    "    x = df.iloc[:, 0:-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    #y = np.reshape(y, (1,-1))\n",
    "    \n",
    "    # Standardize data\n",
    "    #x = scaler.fit_transform(x)\n",
    "    #y = scaler.fit_transform(y)\n",
    "\n",
    "    self.x_data=torch.tensor(x,dtype=torch.float32)\n",
    "    self.y_data=torch.tensor(y,dtype=torch.float32)\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "creditData = FraudDataset('/Users/henriqueribeiro/Downloads/creditcard.csv', fraud= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 227846 \n",
      "Test size: 56961\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(data, split_size):\n",
    "\n",
    "  if not isinstance(split_size, float):\n",
    "    raise TypeError(\"split_size must be a float\")\n",
    "\n",
    "  # divide dataset into train-test subsets\n",
    "  indices = list(range(len(data)))\n",
    "  np.random.shuffle(indices, )\n",
    "\n",
    "  data_size = split_size * len(indices)\n",
    "  split = int(np.floor(data_size))\n",
    "  train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "  train_sampler = SubsetRandomSampler(train_idx)\n",
    "  test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "  print(f'Training size: {len(train_idx)} \\nTest size: {len(test_idx)}')\n",
    "\n",
    "  return train_sampler, test_sampler\n",
    "\n",
    "\n",
    "train, test = split_dataset(creditData.x_data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 1 \n",
      "Test size: 0\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dataset, split_size):\n",
    "\n",
    "    if not isinstance(split_size, float):\n",
    "        raise TypeError(\"split_size must be a float\")\n",
    "\n",
    "    # divide dataset into train-test subsets\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    data_size = split_size * len(indices)\n",
    "    split = int(np.floor(data_size))\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    print(f'Training size: {len(train_idx)} \\nTest size: {len(test_idx)}')\n",
    "\n",
    "    return train_sampler, test_sampler\n",
    "\n",
    "# Create an instance of MyDataset\n",
    "creditData = FraudDataset('/Users/henriqueribeiro/Downloads/creditcard.csv')\n",
    "\n",
    "# Pass the entire dataset to the split_dataset function\n",
    "train_sampler, test_sampler = split_dataset(creditData, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(creditData, batch_size=64, drop_last=True)\n",
    "test_dataloader = DataLoader(creditData, batch_size=64, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dataloader = DataLoader(creditData.x_data, batch_size=64, sampler=train)\n",
    "y_train_dataloader = DataLoader(creditData.y_data, batch_size=64, sampler=train)\n",
    "\n",
    "x_test_dataloader = DataLoader(creditData.x_data, batch_size=64, sampler=test)\n",
    "y_test_dataloader = DataLoader(creditData.y_data, batch_size=64, sampler=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class myDataset(Dataset):\n",
    "#     def __init__(self, path):\n",
    "#         df = pd.read_csv(path)\n",
    "#         df_fraud = df[df['Class'] == 1]\n",
    "#         df_non_fraud = df[df['Class'] == 0]\n",
    "\n",
    "#         # Split features and labels before splitting into train and test\n",
    "#         x_fraud = df_fraud.drop(['Class'], axis=1)\n",
    "#         y_fraud = df_fraud['Class']\n",
    "#         x_non_fraud = df_non_fraud.drop(['Class'], axis=1)\n",
    "#         y_non_fraud = df_non_fraud['Class']\n",
    "\n",
    "#         # Create training and test dataset from df_fraud and df_non_fraud\n",
    "#         train_size_fraud = int(0.8 * len(df_fraud))\n",
    "#         test_size_fraud = len(df_fraud) - train_size_fraud\n",
    "\n",
    "#         train_size_non_fraud = int(0.8 * len(df_non_fraud))\n",
    "#         test_size_non_fraud = len(df_non_fraud) - train_size_non_fraud\n",
    "\n",
    "#         # Combine features and labels and convert to list of tuples\n",
    "#         fraud_data = list(zip(x_fraud.values, y_fraud.values))\n",
    "#         non_fraud_data = list(zip(x_non_fraud.values, y_non_fraud.values))\n",
    "\n",
    "#         #convert fraud_data and non_fraud_data to tensors\n",
    "#         # fraud_data = torch.tensor(fraud_data)\n",
    "#         # non_fraud_data = torch.tensor(non_fraud_data)\n",
    "\n",
    "\n",
    "#         # Split the data\n",
    "#         self.train_fraud, self.test_fraud = torch.utils.data.random_split(fraud_data, [train_size_fraud, test_size_fraud])\n",
    "#         self.train_non_fraud, self.test_non_fraud = torch.utils.data.random_split(non_fraud_data, [train_size_non_fraud, test_size_non_fraud])\n",
    "\n",
    "#         data = []\n",
    "#         for i in range(len(self.train_fraud)):\n",
    "#             teste = self.train_fraud[i]\n",
    "#             # You might need to preprocess 'data' here, depending on your dataset's structure\n",
    "#             data.append(teste)\n",
    "#         self.train_fraud = data\n",
    "\n",
    "#         # #convert to tensors\n",
    "#         self.train_fraud = torch.tensor(self.train_fraud)\n",
    "#         # self.test_fraud = torch.tensor(self.test_fraud)\n",
    "#         # self.train_non_fraud = torch.tensor(self.train_non_fraud)\n",
    "#         # self.test_non_fraud = torch.tensor(self.test_non_fraud)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.train_fraud)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.train_fraud[index], self.test_fraud[index], self.train_non_fraud[index], self.test_non_fraud[index]\n",
    "\n",
    "# # Create dataset instance\n",
    "# dataset = myDataset('/Users/henriqueribeiro/Downloads/creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, nr_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, nr_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nr_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "           nn.Linear(nr_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#define device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "latent_dim = 7\n",
    "nr_features = 30\n",
    "\n",
    "#create optimizer for the generator\n",
    "generator = Generator(latent_dim, nr_features).to(device)\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "#create optimizer for the descriminator\n",
    "discriminator = Discriminator(nr_features)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tGenerator\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 16]             128\n",
      "              ReLU-2                   [-1, 16]               0\n",
      "            Linear-3                   [-1, 32]             544\n",
      "              ReLU-4                   [-1, 32]               0\n",
      "            Linear-5                   [-1, 30]             990\n",
      "================================================================\n",
      "Total params: 1,662\n",
      "Trainable params: 1,662\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\tGenerator')\n",
    "summary(generator, input_size=(latent_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tDiscriminator\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]          31,744\n",
      "              ReLU-2                 [-1, 1024]               0\n",
      "            Linear-3                  [-1, 512]         524,800\n",
      "              ReLU-4                  [-1, 512]               0\n",
      "         Dropout2d-5                  [-1, 512]               0\n",
      "            Linear-6                  [-1, 256]         131,328\n",
      "              ReLU-7                  [-1, 256]               0\n",
      "         Dropout2d-8                  [-1, 256]               0\n",
      "            Linear-9                  [-1, 128]          32,896\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "        Dropout2d-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 64]           8,256\n",
      "             ReLU-13                   [-1, 64]               0\n",
      "        Dropout2d-14                   [-1, 64]               0\n",
      "           Linear-15                   [-1, 32]           2,080\n",
      "             ReLU-16                   [-1, 32]               0\n",
      "        Dropout2d-17                   [-1, 32]               0\n",
      "           Linear-18                   [-1, 16]             528\n",
      "             ReLU-19                   [-1, 16]               0\n",
      "        Dropout2d-20                   [-1, 16]               0\n",
      "           Linear-21                    [-1, 1]              17\n",
      "          Sigmoid-22                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 731,649\n",
      "Trainable params: 731,649\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 2.79\n",
      "Estimated Total Size (MB): 2.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\tDiscriminator')\n",
    "summary(discriminator, input_size=(nr_features,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loss Function + Device + Reset Gradients Funct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define device\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def reset_grad():\n",
    "    discriminator_optimizer.zero_grad()\n",
    "    generator_optimizer.zero_grad()\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(opt_g, cur_batch_size, criterion):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "   \n",
    "    fake_targets = torch.ones((cur_batch_size),  device = device)\n",
    "    \n",
    "    # random noise from uniform distribution\n",
    "    latent_space_samples = torch.randn((cur_batch_size, latent_dim),  device = device)\n",
    "    generated_data = generator(latent_space_samples)  # fake data generated by generator\n",
    "    fake_preds = discriminator(generated_data).reshape(-1)\n",
    "    g_loss = criterion(fake_preds, fake_targets)\n",
    "\n",
    "    g_loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return g_loss, generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_data, opt_d, cur_batch_size):\n",
    "    # Reset gradients\n",
    "    opt_d.zero_grad()\n",
    "    \n",
    "   \n",
    "    #real_labels = df_fraud['Class'].to_numpy() #sendo que estamos \n",
    "    \n",
    "    real_labels = torch.ones((cur_batch_size), device=device)\n",
    "    \n",
    "    real_preds = discriminator(real_data).reshape(-1)\n",
    "    d_loss_real = criterion(real_preds, real_labels)\n",
    "    \n",
    "    fake_labels = torch.zeros((cur_batch_size),  device = device)\n",
    "    # random noise from uniform distribution\n",
    "    latent_space_samples = torch.randn((cur_batch_size, latent_dim),  device = device)\n",
    "    \n",
    "    generated_data = generator(latent_space_samples)  # fake data generated by generator\n",
    "    fake_preds = discriminator(generated_data).reshape(-1)\n",
    "    d_loss_fake = criterion(fake_preds, fake_labels)\n",
    "    \n",
    "    loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    # Adjust the parameters using backprop\n",
    "    opt_d.step()\n",
    "    \n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(num_epochs):\n",
    "    losses_gen = []\n",
    "    losses_dis = []\n",
    "    total_step = len(train_dataloader)\n",
    "    print('Start training...')\n",
    "    for epoch in range(num_epochs):\n",
    "        for index, (real_data, real_labels) in enumerate(train_dataloader):\n",
    "            cur_batch_size = real_data.shape[0]\n",
    "            # Train generator and discriminator\n",
    "            gen_loss, generated_data = train_generator(generator_optimizer, cur_batch_size, criterion)\n",
    "            print(f'Generator loss: {gen_loss:.3f}')\n",
    "            dis_loss = train_discriminator(real_data, discriminator_optimizer, cur_batch_size)\n",
    "            print(f'Discriminator loss {dis_loss:.3f}')\n",
    "\n",
    "            losses_gen.append(gen_loss)\n",
    "            losses_dis.append(dis_loss)\n",
    "\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f} \\n'\n",
    "                  .format(epoch, epoch, index+1, total_step, dis_loss.item(), gen_loss.item()))\n",
    "            \n",
    "    return losses_gen, losses_dis, generated_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [0/0], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [0/0], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [0/0], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [0/0], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss 1.006\n",
      "Epoch [0/0], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [0/0], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [0/0], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [1/1], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [1/1], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [1/1], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [1/1], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [1/1], Step [5/7], d_loss: 1.0064, g_loss: 0.6928 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [1/1], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [1/1], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [2/2], Step [1/7], d_loss: 1.0125, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [2/2], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [2/2], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [2/2], Step [4/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [2/2], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [2/2], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [2/2], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [3/3], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [3/3], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [3/3], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [3/3], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [3/3], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [3/3], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [3/3], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [4/4], Step [1/7], d_loss: 1.0125, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [4/4], Step [2/7], d_loss: 1.0070, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [4/4], Step [3/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [4/4], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [4/4], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [4/4], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [4/4], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [5/5], Step [1/7], d_loss: 1.0133, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [5/5], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [5/5], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [5/5], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [5/5], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [5/5], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [5/5], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [6/6], Step [1/7], d_loss: 1.0129, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [6/6], Step [2/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [6/6], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [6/6], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [6/6], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [6/6], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [6/6], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [7/7], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [7/7], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [7/7], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [7/7], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [7/7], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [7/7], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [7/7], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [8/8], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [8/8], Step [2/7], d_loss: 1.0070, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [8/8], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [8/8], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [8/8], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [8/8], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [8/8], Step [7/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [9/9], Step [1/7], d_loss: 1.0127, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [9/9], Step [2/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.692\n",
      "Discriminator loss 1.006\n",
      "Epoch [9/9], Step [3/7], d_loss: 1.0064, g_loss: 0.6918 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [9/9], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [9/9], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [9/9], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [9/9], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [10/10], Step [1/7], d_loss: 1.0125, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [10/10], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [10/10], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [10/10], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [10/10], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [10/10], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [10/10], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [11/11], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [11/11], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [11/11], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [11/11], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [11/11], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [11/11], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [11/11], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.014\n",
      "Epoch [12/12], Step [1/7], d_loss: 1.0138, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [12/12], Step [2/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [12/12], Step [3/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [12/12], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [12/12], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [12/12], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [12/12], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.014\n",
      "Epoch [13/13], Step [1/7], d_loss: 1.0136, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [13/13], Step [2/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [13/13], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [13/13], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.011\n",
      "Epoch [13/13], Step [5/7], d_loss: 1.0106, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [13/13], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [13/13], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [14/14], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [14/14], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [14/14], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [14/14], Step [4/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [14/14], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [14/14], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [14/14], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.014\n",
      "Epoch [15/15], Step [1/7], d_loss: 1.0138, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [15/15], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [15/15], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [15/15], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [15/15], Step [5/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [15/15], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [15/15], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [16/16], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [16/16], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [16/16], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [16/16], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [16/16], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [16/16], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [16/16], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [17/17], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [17/17], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [17/17], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [17/17], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [17/17], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [17/17], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [17/17], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [18/18], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [18/18], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [18/18], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [18/18], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [18/18], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [18/18], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [18/18], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [19/19], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [19/19], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [19/19], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [19/19], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [19/19], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [19/19], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [19/19], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [20/20], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.008\n",
      "Epoch [20/20], Step [2/7], d_loss: 1.0076, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [20/20], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [20/20], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [20/20], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [20/20], Step [6/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [20/20], Step [7/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [21/21], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [21/21], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [21/21], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [21/21], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [21/21], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [21/21], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [21/21], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [22/22], Step [1/7], d_loss: 1.0127, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [22/22], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [22/22], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [22/22], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [22/22], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [22/22], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [22/22], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [23/23], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [23/23], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [23/23], Step [3/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [23/23], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [23/23], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [23/23], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [23/23], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.015\n",
      "Epoch [24/24], Step [1/7], d_loss: 1.0145, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [24/24], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [24/24], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [24/24], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [24/24], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [24/24], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [24/24], Step [7/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [25/25], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [25/25], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [25/25], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [25/25], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [25/25], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [25/25], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [25/25], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [26/26], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [26/26], Step [2/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [26/26], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [26/26], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [26/26], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [26/26], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [26/26], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [27/27], Step [1/7], d_loss: 1.0128, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [27/27], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [27/27], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [27/27], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [27/27], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [27/27], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [27/27], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [28/28], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [28/28], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [28/28], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [28/28], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [28/28], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [28/28], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [28/28], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [29/29], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [29/29], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [29/29], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [29/29], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.015\n",
      "Epoch [29/29], Step [5/7], d_loss: 1.0149, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [29/29], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [29/29], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [30/30], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [30/30], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [30/30], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [30/30], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [30/30], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [30/30], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [30/30], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [31/31], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.008\n",
      "Epoch [31/31], Step [2/7], d_loss: 1.0082, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [31/31], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [31/31], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [31/31], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [31/31], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [31/31], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [32/32], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [32/32], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [32/32], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [32/32], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [32/32], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [32/32], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [32/32], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [33/33], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [33/33], Step [2/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [33/33], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [33/33], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [33/33], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [33/33], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [33/33], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [34/34], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [34/34], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [34/34], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [34/34], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [34/34], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [34/34], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [34/34], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [35/35], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [35/35], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [35/35], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [35/35], Step [4/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [35/35], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [35/35], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [35/35], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [36/36], Step [1/7], d_loss: 1.0179, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [36/36], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [36/36], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [36/36], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [36/36], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [36/36], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [36/36], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [37/37], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [37/37], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [37/37], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [37/37], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [37/37], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [37/37], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [37/37], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [38/38], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [38/38], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [38/38], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [38/38], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [38/38], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [38/38], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [38/38], Step [7/7], d_loss: 1.0064, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [39/39], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [39/39], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [39/39], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [39/39], Step [4/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [39/39], Step [5/7], d_loss: 1.0064, g_loss: 0.6929 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [39/39], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [39/39], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [40/40], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [40/40], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [40/40], Step [3/7], d_loss: 1.0064, g_loss: 0.6928 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [40/40], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [40/40], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [40/40], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [40/40], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [41/41], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [41/41], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [41/41], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [41/41], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [41/41], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [41/41], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [41/41], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [42/42], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [42/42], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [42/42], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [42/42], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [42/42], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [42/42], Step [6/7], d_loss: 1.0064, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [42/42], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [43/43], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [43/43], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [43/43], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [43/43], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [43/43], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [43/43], Step [6/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [43/43], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [44/44], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [44/44], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [44/44], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [44/44], Step [4/7], d_loss: 1.0074, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [44/44], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [44/44], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [44/44], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [45/45], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [45/45], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [45/45], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [45/45], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [45/45], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [45/45], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [45/45], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [46/46], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [46/46], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [46/46], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [46/46], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [46/46], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [46/46], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [46/46], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [47/47], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [47/47], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [47/47], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [47/47], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [47/47], Step [5/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [47/47], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [47/47], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [48/48], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [48/48], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [48/48], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [48/48], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [48/48], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [48/48], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [48/48], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [49/49], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [49/49], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [49/49], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [49/49], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [49/49], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [49/49], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [49/49], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [50/50], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [50/50], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [50/50], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [50/50], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [50/50], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [50/50], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [50/50], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [51/51], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [51/51], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [51/51], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [51/51], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [51/51], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [51/51], Step [6/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [51/51], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [52/52], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [52/52], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [52/52], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [52/52], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.692\n",
      "Discriminator loss 1.006\n",
      "Epoch [52/52], Step [5/7], d_loss: 1.0064, g_loss: 0.6924 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [52/52], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [52/52], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [53/53], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [53/53], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [53/53], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [53/53], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [53/53], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [53/53], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [53/53], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [54/54], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [54/54], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [54/54], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [54/54], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [54/54], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [54/54], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [54/54], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [55/55], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [55/55], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [55/55], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [55/55], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [55/55], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [55/55], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [55/55], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [56/56], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [56/56], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [56/56], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [56/56], Step [4/7], d_loss: 1.0064, g_loss: 0.6928 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [56/56], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [56/56], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [56/56], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [57/57], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [57/57], Step [2/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [57/57], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [57/57], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [57/57], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [57/57], Step [6/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [57/57], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [58/58], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [58/58], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [58/58], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [58/58], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [58/58], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [58/58], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [58/58], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [59/59], Step [1/7], d_loss: 1.0126, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [59/59], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [59/59], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [59/59], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [59/59], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.008\n",
      "Epoch [59/59], Step [6/7], d_loss: 1.0080, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [59/59], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [60/60], Step [1/7], d_loss: 1.0131, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [60/60], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [60/60], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [60/60], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [60/60], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [60/60], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [60/60], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [61/61], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [61/61], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [61/61], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [61/61], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [61/61], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [61/61], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [61/61], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [62/62], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [62/62], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [62/62], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [62/62], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [62/62], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [62/62], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [62/62], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [63/63], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [63/63], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [63/63], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [63/63], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [63/63], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [63/63], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [63/63], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [64/64], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [64/64], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [64/64], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [64/64], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [64/64], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [64/64], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [64/64], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [65/65], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [65/65], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [65/65], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [65/65], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [65/65], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.008\n",
      "Epoch [65/65], Step [6/7], d_loss: 1.0079, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [65/65], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [66/66], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [66/66], Step [2/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [66/66], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [66/66], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [66/66], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [66/66], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [66/66], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [67/67], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [67/67], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [67/67], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [67/67], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [67/67], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [67/67], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [67/67], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [68/68], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [68/68], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [68/68], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [68/68], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [68/68], Step [5/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [68/68], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [68/68], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [69/69], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [69/69], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [69/69], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [69/69], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [69/69], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [69/69], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [69/69], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [70/70], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [70/70], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [70/70], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [70/70], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [70/70], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [70/70], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [70/70], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [71/71], Step [1/7], d_loss: 1.0125, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [71/71], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [71/71], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [71/71], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [71/71], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [71/71], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [71/71], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [72/72], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [72/72], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [72/72], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [72/72], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [72/72], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [72/72], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [72/72], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [73/73], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [73/73], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [73/73], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [73/73], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [73/73], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [73/73], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [73/73], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [74/74], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [74/74], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [74/74], Step [3/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [74/74], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [74/74], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [74/74], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [74/74], Step [7/7], d_loss: 1.0064, g_loss: 0.6927 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [75/75], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [75/75], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [75/75], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [75/75], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [75/75], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [75/75], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [75/75], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [76/76], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [76/76], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [76/76], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [76/76], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [76/76], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [76/76], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [76/76], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [77/77], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [77/77], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [77/77], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [77/77], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [77/77], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [77/77], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [77/77], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [78/78], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [78/78], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [78/78], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [78/78], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [78/78], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [78/78], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [78/78], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [79/79], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [79/79], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [79/79], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [79/79], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.690\n",
      "Discriminator loss 1.006\n",
      "Epoch [79/79], Step [5/7], d_loss: 1.0064, g_loss: 0.6896 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [79/79], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [79/79], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [80/80], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [80/80], Step [2/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [80/80], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [80/80], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [80/80], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [80/80], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [80/80], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [81/81], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [81/81], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [81/81], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [81/81], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [81/81], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [81/81], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [81/81], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [82/82], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [82/82], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [82/82], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [82/82], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [82/82], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [82/82], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [82/82], Step [7/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [83/83], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [83/83], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [83/83], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [83/83], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [83/83], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [83/83], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [83/83], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [84/84], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [84/84], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [84/84], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [84/84], Step [4/7], d_loss: 1.0064, g_loss: 0.6926 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [84/84], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [84/84], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [84/84], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [85/85], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [85/85], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [85/85], Step [3/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [85/85], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [85/85], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [85/85], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [85/85], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [86/86], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [86/86], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [86/86], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [86/86], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [86/86], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [86/86], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [86/86], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [87/87], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [87/87], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [87/87], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [87/87], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [87/87], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [87/87], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [87/87], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [88/88], Step [1/7], d_loss: 1.0126, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [88/88], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [88/88], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [88/88], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [88/88], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [88/88], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [88/88], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.020\n",
      "Epoch [89/89], Step [1/7], d_loss: 1.0202, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [89/89], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [89/89], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [89/89], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [89/89], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [89/89], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [89/89], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [90/90], Step [1/7], d_loss: 1.0124, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [90/90], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.692\n",
      "Discriminator loss 1.006\n",
      "Epoch [90/90], Step [3/7], d_loss: 1.0064, g_loss: 0.6923 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [90/90], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [90/90], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [90/90], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [90/90], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [91/91], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [91/91], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [91/91], Step [3/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [91/91], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [91/91], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [91/91], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [91/91], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [92/92], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [92/92], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [92/92], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [92/92], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [92/92], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [92/92], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [92/92], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [93/93], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [93/93], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [93/93], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [93/93], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [93/93], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [93/93], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [93/93], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [94/94], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [94/94], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [94/94], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [94/94], Step [4/7], d_loss: 1.0064, g_loss: 0.6929 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [94/94], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [94/94], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [94/94], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [95/95], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [95/95], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [95/95], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [95/95], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [95/95], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [95/95], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [95/95], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [96/96], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [96/96], Step [2/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [96/96], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [96/96], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [96/96], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [96/96], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [96/96], Step [7/7], d_loss: 1.0064, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [97/97], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [97/97], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [97/97], Step [3/7], d_loss: 1.0064, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [97/97], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [97/97], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [97/97], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [97/97], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [98/98], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [98/98], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [98/98], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [98/98], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [98/98], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [98/98], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [98/98], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [99/99], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [99/99], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [99/99], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [99/99], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [99/99], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [99/99], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [99/99], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [100/100], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [100/100], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [100/100], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [100/100], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.015\n",
      "Epoch [100/100], Step [5/7], d_loss: 1.0150, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [100/100], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [100/100], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [101/101], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [101/101], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [101/101], Step [3/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [101/101], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [101/101], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [101/101], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [101/101], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.014\n",
      "Epoch [102/102], Step [1/7], d_loss: 1.0143, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [102/102], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [102/102], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [102/102], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [102/102], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [102/102], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [102/102], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [103/103], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [103/103], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [103/103], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [103/103], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [103/103], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [103/103], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [103/103], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [104/104], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [104/104], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [104/104], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [104/104], Step [4/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [104/104], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [104/104], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [104/104], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [105/105], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [105/105], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [105/105], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [105/105], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [105/105], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [105/105], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [105/105], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [106/106], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [106/106], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [106/106], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [106/106], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [106/106], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [106/106], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [106/106], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [107/107], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [107/107], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [107/107], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [107/107], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [107/107], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [107/107], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [107/107], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [108/108], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [108/108], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [108/108], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [108/108], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [108/108], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [108/108], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [108/108], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [109/109], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [109/109], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [109/109], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [109/109], Step [4/7], d_loss: 1.0064, g_loss: 0.6928 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [109/109], Step [5/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [109/109], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [109/109], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [110/110], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [110/110], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [110/110], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [110/110], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [110/110], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [110/110], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [110/110], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [111/111], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [111/111], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [111/111], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [111/111], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [111/111], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [111/111], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [111/111], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [112/112], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [112/112], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [112/112], Step [3/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [112/112], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [112/112], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [112/112], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [112/112], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [113/113], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [113/113], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [113/113], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [113/113], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [113/113], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [113/113], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [113/113], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [114/114], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [114/114], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [114/114], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [114/114], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [114/114], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [114/114], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [114/114], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [115/115], Step [1/7], d_loss: 1.0123, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [115/115], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [115/115], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [115/115], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [115/115], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [115/115], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [115/115], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [116/116], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [116/116], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [116/116], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [116/116], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [116/116], Step [5/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [116/116], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [116/116], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [117/117], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [117/117], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [117/117], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [117/117], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [117/117], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [117/117], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [117/117], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [118/118], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [118/118], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [118/118], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [118/118], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [118/118], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [118/118], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [118/118], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [119/119], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [119/119], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [119/119], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [119/119], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [119/119], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [119/119], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [119/119], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [120/120], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [120/120], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [120/120], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [120/120], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [120/120], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [120/120], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [120/120], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [121/121], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [121/121], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [121/121], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [121/121], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [121/121], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [121/121], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [121/121], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [122/122], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [122/122], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [122/122], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [122/122], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [122/122], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [122/122], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [122/122], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [123/123], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [123/123], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [123/123], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [123/123], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [123/123], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [123/123], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [123/123], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [124/124], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [124/124], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [124/124], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [124/124], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [124/124], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [124/124], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [124/124], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [125/125], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [125/125], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [125/125], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [125/125], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [125/125], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [125/125], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [125/125], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [126/126], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [126/126], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [126/126], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [126/126], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [126/126], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [126/126], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [126/126], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [127/127], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [127/127], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [127/127], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [127/127], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [127/127], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [127/127], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [127/127], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [128/128], Step [1/7], d_loss: 1.0127, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [128/128], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [128/128], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [128/128], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [128/128], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [128/128], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [128/128], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [129/129], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [129/129], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [129/129], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [129/129], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [129/129], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [129/129], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [129/129], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [130/130], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [130/130], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [130/130], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [130/130], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [130/130], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [130/130], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [130/130], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [131/131], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [131/131], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [131/131], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [131/131], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [131/131], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [131/131], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [131/131], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [132/132], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [132/132], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [132/132], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [132/132], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [132/132], Step [5/7], d_loss: 1.0064, g_loss: 0.6927 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [132/132], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [132/132], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [133/133], Step [1/7], d_loss: 1.0123, g_loss: 0.6927 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [133/133], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [133/133], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [133/133], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [133/133], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [133/133], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [133/133], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [134/134], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [134/134], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [134/134], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [134/134], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [134/134], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [134/134], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [134/134], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [135/135], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [135/135], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [135/135], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [135/135], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [135/135], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [135/135], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [135/135], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [136/136], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [136/136], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [136/136], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [136/136], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [136/136], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [136/136], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [136/136], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [137/137], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [137/137], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [137/137], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [137/137], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [137/137], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [137/137], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [137/137], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [138/138], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [138/138], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [138/138], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [138/138], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [138/138], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [138/138], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [138/138], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [139/139], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [139/139], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [139/139], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [139/139], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [139/139], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [139/139], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [139/139], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [140/140], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [140/140], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [140/140], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [140/140], Step [4/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [140/140], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [140/140], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [140/140], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [141/141], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [141/141], Step [2/7], d_loss: 1.0066, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [141/141], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [141/141], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [141/141], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [141/141], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [141/141], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [142/142], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [142/142], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [142/142], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [142/142], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [142/142], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [142/142], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [142/142], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [143/143], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [143/143], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [143/143], Step [3/7], d_loss: 1.0121, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [143/143], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.008\n",
      "Epoch [143/143], Step [5/7], d_loss: 1.0081, g_loss: 0.6928 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [143/143], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [143/143], Step [7/7], d_loss: 1.0064, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.018\n",
      "Epoch [144/144], Step [1/7], d_loss: 1.0183, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [144/144], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [144/144], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [144/144], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [144/144], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [144/144], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [144/144], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [145/145], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [145/145], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [145/145], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [145/145], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [145/145], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [145/145], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [145/145], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [146/146], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [146/146], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [146/146], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [146/146], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [146/146], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [146/146], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [146/146], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [147/147], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [147/147], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [147/147], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [147/147], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [147/147], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [147/147], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [147/147], Step [7/7], d_loss: 1.0064, g_loss: 0.6928 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [148/148], Step [1/7], d_loss: 1.0125, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [148/148], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [148/148], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [148/148], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [148/148], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [148/148], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [148/148], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [149/149], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [149/149], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [149/149], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [149/149], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [149/149], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [149/149], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [149/149], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [150/150], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [150/150], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [150/150], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [150/150], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [150/150], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [150/150], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [150/150], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [151/151], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [151/151], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [151/151], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [151/151], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [151/151], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [151/151], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [151/151], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [152/152], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [152/152], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [152/152], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [152/152], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [152/152], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [152/152], Step [6/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [152/152], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [153/153], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [153/153], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [153/153], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [153/153], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [153/153], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [153/153], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [153/153], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [154/154], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [154/154], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [154/154], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [154/154], Step [4/7], d_loss: 1.0064, g_loss: 0.6929 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [154/154], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [154/154], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [154/154], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [155/155], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [155/155], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [155/155], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [155/155], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [155/155], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [155/155], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [155/155], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [156/156], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [156/156], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [156/156], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [156/156], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [156/156], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [156/156], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [156/156], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [157/157], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [157/157], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [157/157], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [157/157], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [157/157], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [157/157], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [157/157], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [158/158], Step [1/7], d_loss: 1.0126, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [158/158], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [158/158], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [158/158], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [158/158], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [158/158], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [158/158], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [159/159], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [159/159], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [159/159], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [159/159], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [159/159], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [159/159], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [159/159], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [160/160], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [160/160], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [160/160], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [160/160], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [160/160], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [160/160], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [160/160], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [161/161], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [161/161], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [161/161], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [161/161], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [161/161], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [161/161], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [161/161], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [162/162], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [162/162], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [162/162], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [162/162], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [162/162], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [162/162], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [162/162], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [163/163], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [163/163], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [163/163], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [163/163], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [163/163], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [163/163], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [163/163], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [164/164], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [164/164], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [164/164], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [164/164], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [164/164], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [164/164], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [164/164], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [165/165], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [165/165], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [165/165], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [165/165], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [165/165], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.690\n",
      "Discriminator loss 1.006\n",
      "Epoch [165/165], Step [6/7], d_loss: 1.0064, g_loss: 0.6902 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [165/165], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [166/166], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [166/166], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [166/166], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [166/166], Step [4/7], d_loss: 1.0064, g_loss: 0.6930 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [166/166], Step [5/7], d_loss: 1.0066, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [166/166], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [166/166], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [167/167], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [167/167], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [167/167], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [167/167], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [167/167], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [167/167], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [167/167], Step [7/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [168/168], Step [1/7], d_loss: 1.0126, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [168/168], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [168/168], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [168/168], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [168/168], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [168/168], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [168/168], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [169/169], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [169/169], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [169/169], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [169/169], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [169/169], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [169/169], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [169/169], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [170/170], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [170/170], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [170/170], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [170/170], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [170/170], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [170/170], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [170/170], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [171/171], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [171/171], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [171/171], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [171/171], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [171/171], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [171/171], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [171/171], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [172/172], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [172/172], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [172/172], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [172/172], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [172/172], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [172/172], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [172/172], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [173/173], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [173/173], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [173/173], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [173/173], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [173/173], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [173/173], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [173/173], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [174/174], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [174/174], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [174/174], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [174/174], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [174/174], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [174/174], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [174/174], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [175/175], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [175/175], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [175/175], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [175/175], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [175/175], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [175/175], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [175/175], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [176/176], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [176/176], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [176/176], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [176/176], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [176/176], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [176/176], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [176/176], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [177/177], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [177/177], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [177/177], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [177/177], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [177/177], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [177/177], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [177/177], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [178/178], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [178/178], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [178/178], Step [3/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [178/178], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [178/178], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [178/178], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [178/178], Step [7/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [179/179], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [179/179], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [179/179], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [179/179], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [179/179], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [179/179], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [179/179], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [180/180], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [180/180], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [180/180], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [180/180], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [180/180], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [180/180], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [180/180], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [181/181], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [181/181], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [181/181], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [181/181], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [181/181], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [181/181], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [181/181], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [182/182], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [182/182], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [182/182], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [182/182], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [182/182], Step [5/7], d_loss: 1.0065, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [182/182], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [182/182], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [183/183], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [183/183], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [183/183], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [183/183], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [183/183], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [183/183], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [183/183], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [184/184], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [184/184], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [184/184], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [184/184], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [184/184], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [184/184], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [184/184], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [185/185], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [185/185], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [185/185], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [185/185], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [185/185], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [185/185], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [185/185], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [186/186], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [186/186], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [186/186], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [186/186], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [186/186], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [186/186], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [186/186], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [187/187], Step [1/7], d_loss: 1.0124, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [187/187], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [187/187], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [187/187], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [187/187], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [187/187], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [187/187], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [188/188], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [188/188], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [188/188], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [188/188], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [188/188], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [188/188], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [188/188], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [189/189], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [189/189], Step [2/7], d_loss: 1.0120, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [189/189], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [189/189], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [189/189], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [189/189], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [189/189], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [190/190], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [190/190], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [190/190], Step [3/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [190/190], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [190/190], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [190/190], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [190/190], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [191/191], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [191/191], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.007\n",
      "Epoch [191/191], Step [3/7], d_loss: 1.0067, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [191/191], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [191/191], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [191/191], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [191/191], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [192/192], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [192/192], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [192/192], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [192/192], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [192/192], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [192/192], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [192/192], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [193/193], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [193/193], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [193/193], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [193/193], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [193/193], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [193/193], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [193/193], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [194/194], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [194/194], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.013\n",
      "Epoch [194/194], Step [3/7], d_loss: 1.0125, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [194/194], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [194/194], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [194/194], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [194/194], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [195/195], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [195/195], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [195/195], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [195/195], Step [4/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [195/195], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [195/195], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [195/195], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.024\n",
      "Epoch [196/196], Step [1/7], d_loss: 1.0243, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [196/196], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [196/196], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [196/196], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [196/196], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [196/196], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [196/196], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [197/197], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [197/197], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [197/197], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [197/197], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [197/197], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [197/197], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [197/197], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [198/198], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [198/198], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [198/198], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [198/198], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [198/198], Step [5/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [198/198], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [198/198], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.012\n",
      "Epoch [199/199], Step [1/7], d_loss: 1.0123, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [199/199], Step [2/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [199/199], Step [3/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [199/199], Step [4/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.009\n",
      "Epoch [199/199], Step [5/7], d_loss: 1.0093, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [199/199], Step [6/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n",
      "Generator loss: 0.693\n",
      "Discriminator loss 1.006\n",
      "Epoch [199/199], Step [7/7], d_loss: 1.0064, g_loss: 0.6931 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_gen, losses_dis, generated_data = train_gan(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(losses_gen, losses_dis):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "\n",
    "    #convert losses into numpy\n",
    "    losses_gen = [i.detach().numpy() for i in losses_gen]\n",
    "    losses_dis = [i.detach().numpy() for i in losses_dis]\n",
    "    plt.plot(losses_gen,label=\"Generator\")\n",
    "    plt.plot(losses_dis,label=\"Discriminator\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(losses_gen, losses_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
