{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Body>   \n",
    "<img src=\"data:image/png;base64,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\" width=\"200\" align=\"right\" >   \n",
    "<h1> <b>Advanced Topics on Machine Learning </b> </h1>\n",
    "<p><b>Cátia Teixeira</b> (200808037) | <b>Henrique Bastos</b> (202204383) | <b>Ian Karkles</b> (202200596) | <b>Vitor Pereira</b> (202210497)\n",
    "<p>Master in Data Science and Engineering</p>\n",
    "</Body>\n",
    "Faculdade de Engenharia da Universidade do Porto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation using cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/henriqueribeiro/Downloads/creditcard.csv')\n",
    "\n",
    "#split df into train and test\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (227845, 31)\n",
      "Test shape:  (56962, 31)\n"
     ]
    }
   ],
   "source": [
    "#print the characteristics of the dataframes\n",
    "print('Train shape: ', df_train.shape)\n",
    "print('Test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(Dataset):\n",
    " \n",
    "  def __init__(self, dataframe, fraud = True):\n",
    "    scaler = StandardScaler()\n",
    "    df = dataframe\n",
    "    if fraud:\n",
    "      df = df[df['Class'] == 1]\n",
    " \n",
    "    x = df.iloc[:, 0:-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    #y = np.reshape(y, (1,-1))\n",
    "    \n",
    "    # Standardize data\n",
    "    #x = scaler.fit_transform(x)\n",
    "    #y = scaler.fit_transform(y)\n",
    "\n",
    "    self.x_data=torch.tensor(x,dtype=torch.float32)\n",
    "    self.y_data=torch.tensor(y,dtype=torch.float32)\n",
    "\n",
    "    self.features = x.shape[1]\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "creditData = FraudDataset(df_train, fraud= True)\n",
    "creditDataTest = FraudDataset(df_test, fraud= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(creditData, batch_size=64, drop_last=True)\n",
    "test_dataloader = DataLoader(creditDataTest, batch_size=64, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, nr_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(latent_dim, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(16, nr_features),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nr_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(nr_features, 32),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(16, 1),\n",
    "        \n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#define device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "latent_dim = 7\n",
    "nr_features = 30\n",
    "\n",
    "#create optimizer for the generator\n",
    "generator = Generator(latent_dim, nr_features).to(device)\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "\n",
    "#create optimizer for the descriminator\n",
    "discriminator = Discriminator(nr_features)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tGenerator\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]           8,192\n",
      "              ReLU-2                 [-1, 1024]               0\n",
      "            Linear-3                  [-1, 512]         524,800\n",
      "              ReLU-4                  [-1, 512]               0\n",
      "           Dropout-5                  [-1, 512]               0\n",
      "            Linear-6                  [-1, 256]         131,328\n",
      "              ReLU-7                  [-1, 256]               0\n",
      "           Dropout-8                  [-1, 256]               0\n",
      "            Linear-9                  [-1, 128]          32,896\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "          Dropout-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 64]           8,256\n",
      "             ReLU-13                   [-1, 64]               0\n",
      "          Dropout-14                   [-1, 64]               0\n",
      "           Linear-15                   [-1, 32]           2,080\n",
      "             ReLU-16                   [-1, 32]               0\n",
      "          Dropout-17                   [-1, 32]               0\n",
      "           Linear-18                   [-1, 16]             528\n",
      "             ReLU-19                   [-1, 16]               0\n",
      "          Dropout-20                   [-1, 16]               0\n",
      "           Linear-21                   [-1, 30]             510\n",
      "================================================================\n",
      "Total params: 708,590\n",
      "Trainable params: 708,590\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 2.70\n",
      "Estimated Total Size (MB): 2.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\tGenerator')\n",
    "summary(generator, input_size=(latent_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tDiscriminator\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 32]             992\n",
      "              ReLU-2                   [-1, 32]               0\n",
      "           Dropout-3                   [-1, 32]               0\n",
      "            Linear-4                   [-1, 16]             528\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "           Dropout-6                   [-1, 16]               0\n",
      "            Linear-7                    [-1, 1]              17\n",
      "================================================================\n",
      "Total params: 1,537\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\tDiscriminator')\n",
    "summary(discriminator, input_size=(nr_features,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loss Function + Device + Reset Gradients Funct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(opt_g, cur_batch_size, criterion):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "   \n",
    "    fake_targets = torch.ones((cur_batch_size),  device = device)\n",
    "    fake_targets = fake_targets - 0.1\n",
    "    \n",
    "    # random noise from uniform distribution\n",
    "    latent_space_samples = torch.randn((cur_batch_size, latent_dim),  device = device)\n",
    "    generated_data = generator(latent_space_samples)  # fake data generated by generator\n",
    "    fake_preds = discriminator(generated_data).reshape(-1)\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    g_loss = criterion(fake_preds, fake_targets)\n",
    "\n",
    "\n",
    "    g_loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return g_loss, generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_data, real_labels,  opt_d, cur_batch_size):\n",
    "    # Reset gradients\n",
    "    opt_d.zero_grad()\n",
    "    \n",
    "   \n",
    "    #real_labels = df_fraud['Class'].to_numpy() #sendo que estamos \n",
    "    \n",
    "    real_labels = torch.ones((cur_batch_size), device=device) * 0.9\n",
    "    \n",
    "    real_preds = discriminator(real_data).reshape(-1)\n",
    "    d_loss_real = criterion(real_preds, real_labels)\n",
    "    \n",
    "    fake_labels = torch.zeros((cur_batch_size),  device = device) * 0.1\n",
    "\n",
    "    # random noise from uniform distribution\n",
    "    latent_space_samples = torch.randn((cur_batch_size, latent_dim),  device = device)\n",
    "\n",
    "   \n",
    "    generated_data = generator(latent_space_samples).detach()  # fake data generated by generator\n",
    "    fake_preds = discriminator(generated_data).reshape(-1)\n",
    "    d_loss_fake = criterion(fake_preds, fake_labels)\n",
    "    #d_loss_fake = criterion(fake_preds, fake_labels)\n",
    "    \n",
    "    loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    # Adjust the parameters using backprop\n",
    "    opt_d.step()\n",
    "    \n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, train_df, latent_size=128):\n",
    "        self.lr = 0.0001\n",
    "        self.batch_size = 64\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        \n",
    "        self.dataset = FraudDataset(train_df, fraud= True)\n",
    "        self.dataloader = DataLoader(self.dataset, self.batch_size, shuffle=True)\n",
    "\n",
    "        self.G = Generator(latent_dim=latent_size, nr_features=self.dataset.features).to(device)\n",
    "        self.D = Discriminator(nr_features=self.dataset.features).to(device)\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), self.lr)\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), self.lr)\n",
    "\n",
    "    \n",
    "\n",
    "    def train(self,real_data, cur_batch_size, epochs=1000):\n",
    "        losses_gen = []\n",
    "        losses_dis = []\n",
    "        for epoch in range(epochs):  \n",
    "            for i, (real_data, real_labels)  in enumerate(self.dataloader):\n",
    "                cur_batch_size = real_data.shape[0] #check this\n",
    "                # Train discriminator\n",
    "                d_error = train_discriminator(real_data, real_labels, self.d_optimizer, cur_batch_size)\n",
    "                #g_error = train_generator(generator_optimizer, cur_batch_size, criterion)\n",
    "                #print(f'Discriminator loss {dis_loss:.3f}')\n",
    "\n",
    "                # Clip weights of discriminator\n",
    "                for p in self.D.parameters():\n",
    "                    p.data.clamp_(-self.clip_value, self.clip_value)\n",
    "                \n",
    "                \n",
    "\n",
    "                # Train generator every n_critic iterations\n",
    "                if i % self.n_critic == 0:\n",
    "                    g_error, _ = train_generator(self.g_optimizer, cur_batch_size, criterion)\n",
    "                \n",
    "                \n",
    "               \n",
    "                losses_gen.append(g_error)\n",
    "                losses_dis.append(d_error)\n",
    "\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f} \\n'\n",
    "                .format(epoch, epoch, i+1, len(self.dataloader), d_error.item(), g_error.item()))\n",
    "            \n",
    "        return losses_gen, losses_dis\n",
    "\n",
    "\n",
    "\n",
    "    def sample(self, count):\n",
    "        with torch.no_grad():\n",
    "            z = torch.Tensor(np.random.normal(0, 1, (count, self.latent_size))).to(device)\n",
    "            gen = self.G(z)\n",
    "            return gen.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/0], Step [7/7], d_loss: 10.7527, g_loss: 0.6518 \n",
      "\n",
      "Epoch [1/1], Step [7/7], d_loss: 20.5967, g_loss: 0.6522 \n",
      "\n",
      "Epoch [2/2], Step [7/7], d_loss: 13.4892, g_loss: 0.6525 \n",
      "\n",
      "Epoch [3/3], Step [7/7], d_loss: 9.7841, g_loss: 0.6531 \n",
      "\n",
      "Epoch [4/4], Step [7/7], d_loss: 10.7440, g_loss: 0.6524 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [7/7], d_loss: 15.9070, g_loss: 0.6514 \n",
      "\n",
      "Epoch [6/6], Step [7/7], d_loss: 34.7471, g_loss: 0.6521 \n",
      "\n",
      "Epoch [7/7], Step [7/7], d_loss: 25.8698, g_loss: 0.6506 \n",
      "\n",
      "Epoch [8/8], Step [7/7], d_loss: 10.7491, g_loss: 0.6523 \n",
      "\n",
      "Epoch [9/9], Step [7/7], d_loss: 10.7422, g_loss: 0.6523 \n",
      "\n",
      "Epoch [10/10], Step [7/7], d_loss: 25.9273, g_loss: 0.6523 \n",
      "\n",
      "Epoch [11/11], Step [7/7], d_loss: 14.3926, g_loss: 0.6526 \n",
      "\n",
      "Epoch [12/12], Step [7/7], d_loss: 8.0278, g_loss: 0.6523 \n",
      "\n",
      "Epoch [13/13], Step [7/7], d_loss: 23.2828, g_loss: 0.6520 \n",
      "\n",
      "Epoch [14/14], Step [7/7], d_loss: 14.7778, g_loss: 0.6520 \n",
      "\n",
      "Epoch [15/15], Step [7/7], d_loss: 10.7444, g_loss: 0.6536 \n",
      "\n",
      "Epoch [16/16], Step [7/7], d_loss: 8.9847, g_loss: 0.6523 \n",
      "\n",
      "Epoch [17/17], Step [7/7], d_loss: 25.2435, g_loss: 0.6536 \n",
      "\n",
      "Epoch [18/18], Step [7/7], d_loss: 25.8814, g_loss: 0.6520 \n",
      "\n",
      "Epoch [19/19], Step [7/7], d_loss: 20.6401, g_loss: 0.6538 \n",
      "\n",
      "Epoch [20/20], Step [7/7], d_loss: 10.7488, g_loss: 0.6528 \n",
      "\n",
      "Epoch [21/21], Step [7/7], d_loss: 34.7439, g_loss: 0.6518 \n",
      "\n",
      "Epoch [22/22], Step [7/7], d_loss: 9.7865, g_loss: 0.6523 \n",
      "\n",
      "Epoch [23/23], Step [7/7], d_loss: 10.7454, g_loss: 0.6520 \n",
      "\n",
      "Epoch [24/24], Step [7/7], d_loss: 17.0182, g_loss: 0.6520 \n",
      "\n",
      "Epoch [25/25], Step [7/7], d_loss: 13.1529, g_loss: 0.6508 \n",
      "\n",
      "Epoch [26/26], Step [7/7], d_loss: 10.7454, g_loss: 0.6529 \n",
      "\n",
      "Epoch [27/27], Step [7/7], d_loss: 18.7489, g_loss: 0.6536 \n",
      "\n",
      "Epoch [28/28], Step [7/7], d_loss: 12.8912, g_loss: 0.6509 \n",
      "\n",
      "Epoch [29/29], Step [7/7], d_loss: 19.9619, g_loss: 0.6523 \n",
      "\n",
      "Epoch [30/30], Step [7/7], d_loss: 18.7447, g_loss: 0.6538 \n",
      "\n",
      "Epoch [31/31], Step [7/7], d_loss: 23.3447, g_loss: 0.6508 \n",
      "\n",
      "Epoch [32/32], Step [7/7], d_loss: 18.7468, g_loss: 0.6522 \n",
      "\n",
      "Epoch [33/33], Step [7/7], d_loss: 32.8784, g_loss: 0.6522 \n",
      "\n",
      "Epoch [34/34], Step [7/7], d_loss: 23.8267, g_loss: 0.6519 \n",
      "\n",
      "Epoch [35/35], Step [7/7], d_loss: 28.0148, g_loss: 0.6526 \n",
      "\n",
      "Epoch [36/36], Step [7/7], d_loss: 10.7445, g_loss: 0.6515 \n",
      "\n",
      "Epoch [37/37], Step [7/7], d_loss: 19.5904, g_loss: 0.6521 \n",
      "\n",
      "Epoch [38/38], Step [7/7], d_loss: 10.7537, g_loss: 0.6533 \n",
      "\n",
      "Epoch [39/39], Step [7/7], d_loss: 26.7502, g_loss: 0.6526 \n",
      "\n",
      "Epoch [40/40], Step [7/7], d_loss: 21.3857, g_loss: 0.6537 \n",
      "\n",
      "Epoch [41/41], Step [7/7], d_loss: 13.3434, g_loss: 0.6531 \n",
      "\n",
      "Epoch [42/42], Step [7/7], d_loss: 10.0567, g_loss: 0.6541 \n",
      "\n",
      "Epoch [43/43], Step [7/7], d_loss: 17.0170, g_loss: 0.6517 \n",
      "\n",
      "Epoch [44/44], Step [7/7], d_loss: 19.9538, g_loss: 0.6520 \n",
      "\n",
      "Epoch [45/45], Step [7/7], d_loss: 15.9933, g_loss: 0.6521 \n",
      "\n",
      "Epoch [46/46], Step [7/7], d_loss: 26.7483, g_loss: 0.6518 \n",
      "\n",
      "Epoch [47/47], Step [7/7], d_loss: 29.6894, g_loss: 0.6507 \n",
      "\n",
      "Epoch [48/48], Step [7/7], d_loss: 18.7513, g_loss: 0.6531 \n",
      "\n",
      "Epoch [49/49], Step [7/7], d_loss: 22.3830, g_loss: 0.6528 \n",
      "\n",
      "Epoch [50/50], Step [7/7], d_loss: 16.3987, g_loss: 0.6524 \n",
      "\n",
      "Epoch [51/51], Step [7/7], d_loss: 8.9393, g_loss: 0.6517 \n",
      "\n",
      "Epoch [52/52], Step [7/7], d_loss: 26.7487, g_loss: 0.6523 \n",
      "\n",
      "Epoch [53/53], Step [7/7], d_loss: 28.0403, g_loss: 0.6533 \n",
      "\n",
      "Epoch [54/54], Step [7/7], d_loss: 9.7980, g_loss: 0.6535 \n",
      "\n",
      "Epoch [55/55], Step [7/7], d_loss: 18.7463, g_loss: 0.6529 \n",
      "\n",
      "Epoch [56/56], Step [7/7], d_loss: 11.8116, g_loss: 0.6520 \n",
      "\n",
      "Epoch [57/57], Step [7/7], d_loss: 18.7454, g_loss: 0.6518 \n",
      "\n",
      "Epoch [58/58], Step [7/7], d_loss: 17.8263, g_loss: 0.6527 \n",
      "\n",
      "Epoch [59/59], Step [7/7], d_loss: 18.7520, g_loss: 0.6513 \n",
      "\n",
      "Epoch [60/60], Step [7/7], d_loss: 17.7831, g_loss: 0.6534 \n",
      "\n",
      "Epoch [61/61], Step [7/7], d_loss: 24.3608, g_loss: 0.6524 \n",
      "\n",
      "Epoch [62/62], Step [7/7], d_loss: 10.7455, g_loss: 0.6513 \n",
      "\n",
      "Epoch [63/63], Step [7/7], d_loss: 25.6521, g_loss: 0.6512 \n",
      "\n",
      "Epoch [64/64], Step [7/7], d_loss: 24.2756, g_loss: 0.6524 \n",
      "\n",
      "Epoch [65/65], Step [7/7], d_loss: 15.7868, g_loss: 0.6515 \n",
      "\n",
      "Epoch [66/66], Step [7/7], d_loss: 18.7488, g_loss: 0.6534 \n",
      "\n",
      "Epoch [67/67], Step [7/7], d_loss: 9.7864, g_loss: 0.6514 \n",
      "\n",
      "Epoch [68/68], Step [7/7], d_loss: 9.7819, g_loss: 0.6515 \n",
      "\n",
      "Epoch [69/69], Step [7/7], d_loss: 37.1964, g_loss: 0.6536 \n",
      "\n",
      "Epoch [70/70], Step [7/7], d_loss: 10.7483, g_loss: 0.6523 \n",
      "\n",
      "Epoch [71/71], Step [7/7], d_loss: 36.7752, g_loss: 0.6508 \n",
      "\n",
      "Epoch [72/72], Step [7/7], d_loss: 26.7428, g_loss: 0.6525 \n",
      "\n",
      "Epoch [73/73], Step [7/7], d_loss: 18.6129, g_loss: 0.6507 \n",
      "\n",
      "Epoch [74/74], Step [7/7], d_loss: 36.4725, g_loss: 0.6525 \n",
      "\n",
      "Epoch [75/75], Step [7/7], d_loss: 24.5267, g_loss: 0.6535 \n",
      "\n",
      "Epoch [76/76], Step [7/7], d_loss: 17.8502, g_loss: 0.6524 \n",
      "\n",
      "Epoch [77/77], Step [7/7], d_loss: 19.3585, g_loss: 0.6534 \n",
      "\n",
      "Epoch [78/78], Step [7/7], d_loss: 18.7468, g_loss: 0.6527 \n",
      "\n",
      "Epoch [79/79], Step [7/7], d_loss: 17.1309, g_loss: 0.6529 \n",
      "\n",
      "Epoch [80/80], Step [7/7], d_loss: 16.4297, g_loss: 0.6511 \n",
      "\n",
      "Epoch [81/81], Step [7/7], d_loss: 9.4872, g_loss: 0.6506 \n",
      "\n",
      "Epoch [82/82], Step [7/7], d_loss: 29.7662, g_loss: 0.6532 \n",
      "\n",
      "Epoch [83/83], Step [7/7], d_loss: 18.6443, g_loss: 0.6515 \n",
      "\n",
      "Epoch [84/84], Step [7/7], d_loss: 15.2009, g_loss: 0.6508 \n",
      "\n",
      "Epoch [85/85], Step [7/7], d_loss: 18.9796, g_loss: 0.6521 \n",
      "\n",
      "Epoch [86/86], Step [7/7], d_loss: 30.9341, g_loss: 0.6517 \n",
      "\n",
      "Epoch [87/87], Step [7/7], d_loss: 9.8441, g_loss: 0.6526 \n",
      "\n",
      "Epoch [88/88], Step [7/7], d_loss: 17.8271, g_loss: 0.6522 \n",
      "\n",
      "Epoch [89/89], Step [7/7], d_loss: 10.7497, g_loss: 0.6517 \n",
      "\n",
      "Epoch [90/90], Step [7/7], d_loss: 22.5813, g_loss: 0.6507 \n",
      "\n",
      "Epoch [91/91], Step [7/7], d_loss: 18.7500, g_loss: 0.6533 \n",
      "\n",
      "Epoch [92/92], Step [7/7], d_loss: 18.1217, g_loss: 0.6555 \n",
      "\n",
      "Epoch [93/93], Step [7/7], d_loss: 18.7435, g_loss: 0.6513 \n",
      "\n",
      "Epoch [94/94], Step [7/7], d_loss: 18.7460, g_loss: 0.6522 \n",
      "\n",
      "Epoch [95/95], Step [7/7], d_loss: 13.8220, g_loss: 0.6506 \n",
      "\n",
      "Epoch [96/96], Step [7/7], d_loss: 10.7482, g_loss: 0.6518 \n",
      "\n",
      "Epoch [97/97], Step [7/7], d_loss: 10.7454, g_loss: 0.6530 \n",
      "\n",
      "Epoch [98/98], Step [7/7], d_loss: 10.7493, g_loss: 0.6523 \n",
      "\n",
      "Epoch [99/99], Step [7/7], d_loss: 10.7471, g_loss: 0.6515 \n",
      "\n",
      "Epoch [100/100], Step [7/7], d_loss: 18.7450, g_loss: 0.6507 \n",
      "\n",
      "Epoch [101/101], Step [7/7], d_loss: 28.7887, g_loss: 0.6517 \n",
      "\n",
      "Epoch [102/102], Step [7/7], d_loss: 26.7473, g_loss: 0.6537 \n",
      "\n",
      "Epoch [103/103], Step [7/7], d_loss: 16.5309, g_loss: 0.6529 \n",
      "\n",
      "Epoch [104/104], Step [7/7], d_loss: 17.9535, g_loss: 0.6537 \n",
      "\n",
      "Epoch [105/105], Step [7/7], d_loss: 17.8441, g_loss: 0.6520 \n",
      "\n",
      "Epoch [106/106], Step [7/7], d_loss: 34.7547, g_loss: 0.6508 \n",
      "\n",
      "Epoch [107/107], Step [7/7], d_loss: 14.5000, g_loss: 0.6525 \n",
      "\n",
      "Epoch [108/108], Step [7/7], d_loss: 9.9050, g_loss: 0.6535 \n",
      "\n",
      "Epoch [109/109], Step [7/7], d_loss: 15.1833, g_loss: 0.6532 \n",
      "\n",
      "Epoch [110/110], Step [7/7], d_loss: 12.5318, g_loss: 0.6512 \n",
      "\n",
      "Epoch [111/111], Step [7/7], d_loss: 18.7490, g_loss: 0.6512 \n",
      "\n",
      "Epoch [112/112], Step [7/7], d_loss: 18.2919, g_loss: 0.6507 \n",
      "\n",
      "Epoch [113/113], Step [7/7], d_loss: 10.7466, g_loss: 0.6515 \n",
      "\n",
      "Epoch [114/114], Step [7/7], d_loss: 26.7549, g_loss: 0.6521 \n",
      "\n",
      "Epoch [115/115], Step [7/7], d_loss: 9.9029, g_loss: 0.6517 \n",
      "\n",
      "Epoch [116/116], Step [7/7], d_loss: 10.7500, g_loss: 0.6533 \n",
      "\n",
      "Epoch [117/117], Step [7/7], d_loss: 10.5264, g_loss: 0.6526 \n",
      "\n",
      "Epoch [118/118], Step [7/7], d_loss: 16.3195, g_loss: 0.6517 \n",
      "\n",
      "Epoch [119/119], Step [7/7], d_loss: 13.2208, g_loss: 0.6520 \n",
      "\n",
      "Epoch [120/120], Step [7/7], d_loss: 14.9112, g_loss: 0.6552 \n",
      "\n",
      "Epoch [121/121], Step [7/7], d_loss: 18.0701, g_loss: 0.6526 \n",
      "\n",
      "Epoch [122/122], Step [7/7], d_loss: 14.2538, g_loss: 0.6518 \n",
      "\n",
      "Epoch [123/123], Step [7/7], d_loss: 19.9234, g_loss: 0.6524 \n",
      "\n",
      "Epoch [124/124], Step [7/7], d_loss: 9.8852, g_loss: 0.6504 \n",
      "\n",
      "Epoch [125/125], Step [7/7], d_loss: 10.7462, g_loss: 0.6526 \n",
      "\n",
      "Epoch [126/126], Step [7/7], d_loss: 9.8668, g_loss: 0.6518 \n",
      "\n",
      "Epoch [127/127], Step [7/7], d_loss: 9.7863, g_loss: 0.6503 \n",
      "\n",
      "Epoch [128/128], Step [7/7], d_loss: 11.6930, g_loss: 0.6507 \n",
      "\n",
      "Epoch [129/129], Step [7/7], d_loss: 16.7599, g_loss: 0.6518 \n",
      "\n",
      "Epoch [130/130], Step [7/7], d_loss: 10.7408, g_loss: 0.6523 \n",
      "\n",
      "Epoch [131/131], Step [7/7], d_loss: 10.2039, g_loss: 0.6520 \n",
      "\n",
      "Epoch [132/132], Step [7/7], d_loss: 15.2503, g_loss: 0.6528 \n",
      "\n",
      "Epoch [133/133], Step [7/7], d_loss: 14.8372, g_loss: 0.6508 \n",
      "\n",
      "Epoch [134/134], Step [7/7], d_loss: 10.8151, g_loss: 0.6523 \n",
      "\n",
      "Epoch [135/135], Step [7/7], d_loss: 20.1957, g_loss: 0.6524 \n",
      "\n",
      "Epoch [136/136], Step [7/7], d_loss: 26.7422, g_loss: 0.6527 \n",
      "\n",
      "Epoch [137/137], Step [7/7], d_loss: 14.5269, g_loss: 0.6532 \n",
      "\n",
      "Epoch [138/138], Step [7/7], d_loss: 25.8236, g_loss: 0.6542 \n",
      "\n",
      "Epoch [139/139], Step [7/7], d_loss: 10.7528, g_loss: 0.6514 \n",
      "\n",
      "Epoch [140/140], Step [7/7], d_loss: 10.7431, g_loss: 0.6538 \n",
      "\n",
      "Epoch [141/141], Step [7/7], d_loss: 12.4181, g_loss: 0.6526 \n",
      "\n",
      "Epoch [142/142], Step [7/7], d_loss: 26.7512, g_loss: 0.6521 \n",
      "\n",
      "Epoch [143/143], Step [7/7], d_loss: 9.7842, g_loss: 0.6520 \n",
      "\n",
      "Epoch [144/144], Step [7/7], d_loss: 18.2921, g_loss: 0.6518 \n",
      "\n",
      "Epoch [145/145], Step [7/7], d_loss: 26.7497, g_loss: 0.6524 \n",
      "\n",
      "Epoch [146/146], Step [7/7], d_loss: 9.8950, g_loss: 0.6520 \n",
      "\n",
      "Epoch [147/147], Step [7/7], d_loss: 10.7499, g_loss: 0.6529 \n",
      "\n",
      "Epoch [148/148], Step [7/7], d_loss: 26.7483, g_loss: 0.6512 \n",
      "\n",
      "Epoch [149/149], Step [7/7], d_loss: 23.4965, g_loss: 0.6532 \n",
      "\n",
      "Epoch [150/150], Step [7/7], d_loss: 17.8625, g_loss: 0.6531 \n",
      "\n",
      "Epoch [151/151], Step [7/7], d_loss: 18.7499, g_loss: 0.6533 \n",
      "\n",
      "Epoch [152/152], Step [7/7], d_loss: 18.7462, g_loss: 0.6528 \n",
      "\n",
      "Epoch [153/153], Step [7/7], d_loss: 10.7495, g_loss: 0.6509 \n",
      "\n",
      "Epoch [154/154], Step [7/7], d_loss: 8.8787, g_loss: 0.6510 \n",
      "\n",
      "Epoch [155/155], Step [7/7], d_loss: 11.1093, g_loss: 0.6537 \n",
      "\n",
      "Epoch [156/156], Step [7/7], d_loss: 26.7481, g_loss: 0.6527 \n",
      "\n",
      "Epoch [157/157], Step [7/7], d_loss: 17.8336, g_loss: 0.6523 \n",
      "\n",
      "Epoch [158/158], Step [7/7], d_loss: 26.7449, g_loss: 0.6534 \n",
      "\n",
      "Epoch [159/159], Step [7/7], d_loss: 10.7559, g_loss: 0.6530 \n",
      "\n",
      "Epoch [160/160], Step [7/7], d_loss: 12.6375, g_loss: 0.6510 \n",
      "\n",
      "Epoch [161/161], Step [7/7], d_loss: 26.7470, g_loss: 0.6523 \n",
      "\n",
      "Epoch [162/162], Step [7/7], d_loss: 18.7468, g_loss: 0.6513 \n",
      "\n",
      "Epoch [163/163], Step [7/7], d_loss: 17.8732, g_loss: 0.6534 \n",
      "\n",
      "Epoch [164/164], Step [7/7], d_loss: 24.0738, g_loss: 0.6523 \n",
      "\n",
      "Epoch [165/165], Step [7/7], d_loss: 20.9981, g_loss: 0.6521 \n",
      "\n",
      "Epoch [166/166], Step [7/7], d_loss: 9.8691, g_loss: 0.6531 \n",
      "\n",
      "Epoch [167/167], Step [7/7], d_loss: 18.3375, g_loss: 0.6511 \n",
      "\n",
      "Epoch [168/168], Step [7/7], d_loss: 17.8861, g_loss: 0.6496 \n",
      "\n",
      "Epoch [169/169], Step [7/7], d_loss: 28.2834, g_loss: 0.6524 \n",
      "\n",
      "Epoch [170/170], Step [7/7], d_loss: 12.6546, g_loss: 0.6515 \n",
      "\n",
      "Epoch [171/171], Step [7/7], d_loss: 26.7435, g_loss: 0.6528 \n",
      "\n",
      "Epoch [172/172], Step [7/7], d_loss: 38.8039, g_loss: 0.6528 \n",
      "\n",
      "Epoch [173/173], Step [7/7], d_loss: 49.7877, g_loss: 0.6531 \n",
      "\n",
      "Epoch [174/174], Step [7/7], d_loss: 9.7879, g_loss: 0.6499 \n",
      "\n",
      "Epoch [175/175], Step [7/7], d_loss: 30.1806, g_loss: 0.6516 \n",
      "\n",
      "Epoch [176/176], Step [7/7], d_loss: 9.9056, g_loss: 0.6529 \n",
      "\n",
      "Epoch [177/177], Step [7/7], d_loss: 15.0220, g_loss: 0.6517 \n",
      "\n",
      "Epoch [178/178], Step [7/7], d_loss: 10.7453, g_loss: 0.6536 \n",
      "\n",
      "Epoch [179/179], Step [7/7], d_loss: 21.4375, g_loss: 0.6520 \n",
      "\n",
      "Epoch [180/180], Step [7/7], d_loss: 24.6234, g_loss: 0.6515 \n",
      "\n",
      "Epoch [181/181], Step [7/7], d_loss: 14.0519, g_loss: 0.6542 \n",
      "\n",
      "Epoch [182/182], Step [7/7], d_loss: 44.2602, g_loss: 0.6521 \n",
      "\n",
      "Epoch [183/183], Step [7/7], d_loss: 26.7443, g_loss: 0.6518 \n",
      "\n",
      "Epoch [184/184], Step [7/7], d_loss: 14.8698, g_loss: 0.6527 \n",
      "\n",
      "Epoch [185/185], Step [7/7], d_loss: 10.7437, g_loss: 0.6514 \n",
      "\n",
      "Epoch [186/186], Step [7/7], d_loss: 26.7480, g_loss: 0.6504 \n",
      "\n",
      "Epoch [187/187], Step [7/7], d_loss: 26.7550, g_loss: 0.6519 \n",
      "\n",
      "Epoch [188/188], Step [7/7], d_loss: 18.7509, g_loss: 0.6523 \n",
      "\n",
      "Epoch [189/189], Step [7/7], d_loss: 17.7812, g_loss: 0.6527 \n",
      "\n",
      "Epoch [190/190], Step [7/7], d_loss: 23.9896, g_loss: 0.6526 \n",
      "\n",
      "Epoch [191/191], Step [7/7], d_loss: 10.7497, g_loss: 0.6527 \n",
      "\n",
      "Epoch [192/192], Step [7/7], d_loss: 26.7488, g_loss: 0.6524 \n",
      "\n",
      "Epoch [193/193], Step [7/7], d_loss: 9.5637, g_loss: 0.6538 \n",
      "\n",
      "Epoch [194/194], Step [7/7], d_loss: 10.6675, g_loss: 0.6526 \n",
      "\n",
      "Epoch [195/195], Step [7/7], d_loss: 9.8401, g_loss: 0.6523 \n",
      "\n",
      "Epoch [196/196], Step [7/7], d_loss: 10.7379, g_loss: 0.6521 \n",
      "\n",
      "Epoch [197/197], Step [7/7], d_loss: 10.7486, g_loss: 0.6528 \n",
      "\n",
      "Epoch [198/198], Step [7/7], d_loss: 18.7483, g_loss: 0.6538 \n",
      "\n",
      "Epoch [199/199], Step [7/7], d_loss: 10.7385, g_loss: 0.6530 \n",
      "\n",
      "Epoch [200/200], Step [7/7], d_loss: 10.7466, g_loss: 0.6531 \n",
      "\n",
      "Epoch [201/201], Step [7/7], d_loss: 24.8350, g_loss: 0.6508 \n",
      "\n",
      "Epoch [202/202], Step [7/7], d_loss: 18.2090, g_loss: 0.6531 \n",
      "\n",
      "Epoch [203/203], Step [7/7], d_loss: 22.0841, g_loss: 0.6531 \n",
      "\n",
      "Epoch [204/204], Step [7/7], d_loss: 9.7882, g_loss: 0.6519 \n",
      "\n",
      "Epoch [205/205], Step [7/7], d_loss: 15.3275, g_loss: 0.6503 \n",
      "\n",
      "Epoch [206/206], Step [7/7], d_loss: 15.7173, g_loss: 0.6510 \n",
      "\n",
      "Epoch [207/207], Step [7/7], d_loss: 10.7468, g_loss: 0.6533 \n",
      "\n",
      "Epoch [208/208], Step [7/7], d_loss: 9.8976, g_loss: 0.6541 \n",
      "\n",
      "Epoch [209/209], Step [7/7], d_loss: 16.8940, g_loss: 0.6517 \n",
      "\n",
      "Epoch [210/210], Step [7/7], d_loss: 8.9262, g_loss: 0.6530 \n",
      "\n",
      "Epoch [211/211], Step [7/7], d_loss: 26.7503, g_loss: 0.6527 \n",
      "\n",
      "Epoch [212/212], Step [7/7], d_loss: 8.6713, g_loss: 0.6537 \n",
      "\n",
      "Epoch [213/213], Step [7/7], d_loss: 33.8807, g_loss: 0.6528 \n",
      "\n",
      "Epoch [214/214], Step [7/7], d_loss: 17.9057, g_loss: 0.6525 \n",
      "\n",
      "Epoch [215/215], Step [7/7], d_loss: 9.8197, g_loss: 0.6534 \n",
      "\n",
      "Epoch [216/216], Step [7/7], d_loss: 11.3219, g_loss: 0.6540 \n",
      "\n",
      "Epoch [217/217], Step [7/7], d_loss: 24.5641, g_loss: 0.6540 \n",
      "\n",
      "Epoch [218/218], Step [7/7], d_loss: 10.7398, g_loss: 0.6518 \n",
      "\n",
      "Epoch [219/219], Step [7/7], d_loss: 11.6235, g_loss: 0.6527 \n",
      "\n",
      "Epoch [220/220], Step [7/7], d_loss: 10.7516, g_loss: 0.6518 \n",
      "\n",
      "Epoch [221/221], Step [7/7], d_loss: 10.7463, g_loss: 0.6526 \n",
      "\n",
      "Epoch [222/222], Step [7/7], d_loss: 34.7490, g_loss: 0.6516 \n",
      "\n",
      "Epoch [223/223], Step [7/7], d_loss: 9.8053, g_loss: 0.6514 \n",
      "\n",
      "Epoch [224/224], Step [7/7], d_loss: 10.7522, g_loss: 0.6509 \n",
      "\n",
      "Epoch [225/225], Step [7/7], d_loss: 10.0029, g_loss: 0.6533 \n",
      "\n",
      "Epoch [226/226], Step [7/7], d_loss: 9.9010, g_loss: 0.6530 \n",
      "\n",
      "Epoch [227/227], Step [7/7], d_loss: 8.0202, g_loss: 0.6534 \n",
      "\n",
      "Epoch [228/228], Step [7/7], d_loss: 25.8106, g_loss: 0.6507 \n",
      "\n",
      "Epoch [229/229], Step [7/7], d_loss: 9.9013, g_loss: 0.6528 \n",
      "\n",
      "Epoch [230/230], Step [7/7], d_loss: 17.0515, g_loss: 0.6516 \n",
      "\n",
      "Epoch [231/231], Step [7/7], d_loss: 12.7994, g_loss: 0.6521 \n",
      "\n",
      "Epoch [232/232], Step [7/7], d_loss: 8.0020, g_loss: 0.6521 \n",
      "\n",
      "Epoch [233/233], Step [7/7], d_loss: 10.7523, g_loss: 0.6532 \n",
      "\n",
      "Epoch [234/234], Step [7/7], d_loss: 7.9192, g_loss: 0.6512 \n",
      "\n",
      "Epoch [235/235], Step [7/7], d_loss: 25.0807, g_loss: 0.6538 \n",
      "\n",
      "Epoch [236/236], Step [7/7], d_loss: 10.7440, g_loss: 0.6550 \n",
      "\n",
      "Epoch [237/237], Step [7/7], d_loss: 18.7440, g_loss: 0.6530 \n",
      "\n",
      "Epoch [238/238], Step [7/7], d_loss: 10.7492, g_loss: 0.6525 \n",
      "\n",
      "Epoch [239/239], Step [7/7], d_loss: 10.7521, g_loss: 0.6499 \n",
      "\n",
      "Epoch [240/240], Step [7/7], d_loss: 17.8017, g_loss: 0.6520 \n",
      "\n",
      "Epoch [241/241], Step [7/7], d_loss: 9.7794, g_loss: 0.6543 \n",
      "\n",
      "Epoch [242/242], Step [7/7], d_loss: 10.7473, g_loss: 0.6522 \n",
      "\n",
      "Epoch [243/243], Step [7/7], d_loss: 17.0317, g_loss: 0.6518 \n",
      "\n",
      "Epoch [244/244], Step [7/7], d_loss: 18.7487, g_loss: 0.6510 \n",
      "\n",
      "Epoch [245/245], Step [7/7], d_loss: 25.3374, g_loss: 0.6518 \n",
      "\n",
      "Epoch [246/246], Step [7/7], d_loss: 17.0583, g_loss: 0.6526 \n",
      "\n",
      "Epoch [247/247], Step [7/7], d_loss: 18.7419, g_loss: 0.6512 \n",
      "\n",
      "Epoch [248/248], Step [7/7], d_loss: 10.7546, g_loss: 0.6532 \n",
      "\n",
      "Epoch [249/249], Step [7/7], d_loss: 11.4453, g_loss: 0.6529 \n",
      "\n",
      "Epoch [250/250], Step [7/7], d_loss: 18.7442, g_loss: 0.6526 \n",
      "\n",
      "Epoch [251/251], Step [7/7], d_loss: 18.7440, g_loss: 0.6522 \n",
      "\n",
      "Epoch [252/252], Step [7/7], d_loss: 10.7444, g_loss: 0.6531 \n",
      "\n",
      "Epoch [253/253], Step [7/7], d_loss: 11.3954, g_loss: 0.6522 \n",
      "\n",
      "Epoch [254/254], Step [7/7], d_loss: 34.7508, g_loss: 0.6516 \n",
      "\n",
      "Epoch [255/255], Step [7/7], d_loss: 18.7494, g_loss: 0.6522 \n",
      "\n",
      "Epoch [256/256], Step [7/7], d_loss: 14.9106, g_loss: 0.6551 \n",
      "\n",
      "Epoch [257/257], Step [7/7], d_loss: 18.7479, g_loss: 0.6534 \n",
      "\n",
      "Epoch [258/258], Step [7/7], d_loss: 24.9966, g_loss: 0.6512 \n",
      "\n",
      "Epoch [259/259], Step [7/7], d_loss: 18.7477, g_loss: 0.6521 \n",
      "\n",
      "Epoch [260/260], Step [7/7], d_loss: 10.7462, g_loss: 0.6528 \n",
      "\n",
      "Epoch [261/261], Step [7/7], d_loss: 16.9584, g_loss: 0.6519 \n",
      "\n",
      "Epoch [262/262], Step [7/7], d_loss: 19.1920, g_loss: 0.6528 \n",
      "\n",
      "Epoch [263/263], Step [7/7], d_loss: 10.7391, g_loss: 0.6513 \n",
      "\n",
      "Epoch [264/264], Step [7/7], d_loss: 14.2731, g_loss: 0.6511 \n",
      "\n",
      "Epoch [265/265], Step [7/7], d_loss: 18.5385, g_loss: 0.6517 \n",
      "\n",
      "Epoch [266/266], Step [7/7], d_loss: 18.7482, g_loss: 0.6532 \n",
      "\n",
      "Epoch [267/267], Step [7/7], d_loss: 8.8795, g_loss: 0.6534 \n",
      "\n",
      "Epoch [268/268], Step [7/7], d_loss: 9.7161, g_loss: 0.6509 \n",
      "\n",
      "Epoch [269/269], Step [7/7], d_loss: 39.5036, g_loss: 0.6513 \n",
      "\n",
      "Epoch [270/270], Step [7/7], d_loss: 12.6130, g_loss: 0.6509 \n",
      "\n",
      "Epoch [271/271], Step [7/7], d_loss: 18.7476, g_loss: 0.6534 \n",
      "\n",
      "Epoch [272/272], Step [7/7], d_loss: 10.7518, g_loss: 0.6536 \n",
      "\n",
      "Epoch [273/273], Step [7/7], d_loss: 18.7437, g_loss: 0.6519 \n",
      "\n",
      "Epoch [274/274], Step [7/7], d_loss: 12.7760, g_loss: 0.6524 \n",
      "\n",
      "Epoch [275/275], Step [7/7], d_loss: 14.4884, g_loss: 0.6525 \n",
      "\n",
      "Epoch [276/276], Step [7/7], d_loss: 17.4671, g_loss: 0.6514 \n",
      "\n",
      "Epoch [277/277], Step [7/7], d_loss: 10.7440, g_loss: 0.6533 \n",
      "\n",
      "Epoch [278/278], Step [7/7], d_loss: 17.7961, g_loss: 0.6521 \n",
      "\n",
      "Epoch [279/279], Step [7/7], d_loss: 14.9182, g_loss: 0.6527 \n",
      "\n",
      "Epoch [280/280], Step [7/7], d_loss: 8.9131, g_loss: 0.6522 \n",
      "\n",
      "Epoch [281/281], Step [7/7], d_loss: 18.7471, g_loss: 0.6503 \n",
      "\n",
      "Epoch [282/282], Step [7/7], d_loss: 22.8901, g_loss: 0.6542 \n",
      "\n",
      "Epoch [283/283], Step [7/7], d_loss: 19.8851, g_loss: 0.6539 \n",
      "\n",
      "Epoch [284/284], Step [7/7], d_loss: 10.7446, g_loss: 0.6526 \n",
      "\n",
      "Epoch [285/285], Step [7/7], d_loss: 17.8481, g_loss: 0.6532 \n",
      "\n",
      "Epoch [286/286], Step [7/7], d_loss: 25.0243, g_loss: 0.6501 \n",
      "\n",
      "Epoch [287/287], Step [7/7], d_loss: 18.7482, g_loss: 0.6510 \n",
      "\n",
      "Epoch [288/288], Step [7/7], d_loss: 10.7484, g_loss: 0.6517 \n",
      "\n",
      "Epoch [289/289], Step [7/7], d_loss: 18.7482, g_loss: 0.6541 \n",
      "\n",
      "Epoch [290/290], Step [7/7], d_loss: 10.7458, g_loss: 0.6526 \n",
      "\n",
      "Epoch [291/291], Step [7/7], d_loss: 12.8586, g_loss: 0.6525 \n",
      "\n",
      "Epoch [292/292], Step [7/7], d_loss: 20.7124, g_loss: 0.6519 \n",
      "\n",
      "Epoch [293/293], Step [7/7], d_loss: 23.5884, g_loss: 0.6509 \n",
      "\n",
      "Epoch [294/294], Step [7/7], d_loss: 33.4836, g_loss: 0.6526 \n",
      "\n",
      "Epoch [295/295], Step [7/7], d_loss: 10.6746, g_loss: 0.6510 \n",
      "\n",
      "Epoch [296/296], Step [7/7], d_loss: 18.8558, g_loss: 0.6509 \n",
      "\n",
      "Epoch [297/297], Step [7/7], d_loss: 10.9565, g_loss: 0.6518 \n",
      "\n",
      "Epoch [298/298], Step [7/7], d_loss: 10.8548, g_loss: 0.6516 \n",
      "\n",
      "Epoch [299/299], Step [7/7], d_loss: 20.6504, g_loss: 0.6533 \n",
      "\n",
      "Epoch [300/300], Step [7/7], d_loss: 17.6496, g_loss: 0.6525 \n",
      "\n",
      "Epoch [301/301], Step [7/7], d_loss: 10.7501, g_loss: 0.6518 \n",
      "\n",
      "Epoch [302/302], Step [7/7], d_loss: 18.7481, g_loss: 0.6507 \n",
      "\n",
      "Epoch [303/303], Step [7/7], d_loss: 10.2012, g_loss: 0.6520 \n",
      "\n",
      "Epoch [304/304], Step [7/7], d_loss: 10.2156, g_loss: 0.6514 \n",
      "\n",
      "Epoch [305/305], Step [7/7], d_loss: 18.7456, g_loss: 0.6513 \n",
      "\n",
      "Epoch [306/306], Step [7/7], d_loss: 18.7470, g_loss: 0.6517 \n",
      "\n",
      "Epoch [307/307], Step [7/7], d_loss: 21.7768, g_loss: 0.6528 \n",
      "\n",
      "Epoch [308/308], Step [7/7], d_loss: 26.1280, g_loss: 0.6542 \n",
      "\n",
      "Epoch [309/309], Step [7/7], d_loss: 18.7494, g_loss: 0.6528 \n",
      "\n",
      "Epoch [310/310], Step [7/7], d_loss: 18.4757, g_loss: 0.6531 \n",
      "\n",
      "Epoch [311/311], Step [7/7], d_loss: 28.4812, g_loss: 0.6511 \n",
      "\n",
      "Epoch [312/312], Step [7/7], d_loss: 11.8798, g_loss: 0.6524 \n",
      "\n",
      "Epoch [313/313], Step [7/7], d_loss: 17.8794, g_loss: 0.6525 \n",
      "\n",
      "Epoch [314/314], Step [7/7], d_loss: 10.7574, g_loss: 0.6531 \n",
      "\n",
      "Epoch [315/315], Step [7/7], d_loss: 18.7530, g_loss: 0.6521 \n",
      "\n",
      "Epoch [316/316], Step [7/7], d_loss: 29.0655, g_loss: 0.6515 \n",
      "\n",
      "Epoch [317/317], Step [7/7], d_loss: 10.7487, g_loss: 0.6512 \n",
      "\n",
      "Epoch [318/318], Step [7/7], d_loss: 18.7432, g_loss: 0.6525 \n",
      "\n",
      "Epoch [319/319], Step [7/7], d_loss: 9.9214, g_loss: 0.6546 \n",
      "\n",
      "Epoch [320/320], Step [7/7], d_loss: 12.7992, g_loss: 0.6516 \n",
      "\n",
      "Epoch [321/321], Step [7/7], d_loss: 8.9495, g_loss: 0.6520 \n",
      "\n",
      "Epoch [322/322], Step [7/7], d_loss: 16.6624, g_loss: 0.6511 \n",
      "\n",
      "Epoch [323/323], Step [7/7], d_loss: 30.2418, g_loss: 0.6529 \n",
      "\n",
      "Epoch [324/324], Step [7/7], d_loss: 11.5130, g_loss: 0.6507 \n",
      "\n",
      "Epoch [325/325], Step [7/7], d_loss: 10.7430, g_loss: 0.6518 \n",
      "\n",
      "Epoch [326/326], Step [7/7], d_loss: 15.3641, g_loss: 0.6500 \n",
      "\n",
      "Epoch [327/327], Step [7/7], d_loss: 10.7458, g_loss: 0.6521 \n",
      "\n",
      "Epoch [328/328], Step [7/7], d_loss: 18.7455, g_loss: 0.6523 \n",
      "\n",
      "Epoch [329/329], Step [7/7], d_loss: 14.4754, g_loss: 0.6497 \n",
      "\n",
      "Epoch [330/330], Step [7/7], d_loss: 16.4538, g_loss: 0.6523 \n",
      "\n",
      "Epoch [331/331], Step [7/7], d_loss: 26.7480, g_loss: 0.6524 \n",
      "\n",
      "Epoch [332/332], Step [7/7], d_loss: 24.0431, g_loss: 0.6517 \n",
      "\n",
      "Epoch [333/333], Step [7/7], d_loss: 13.2138, g_loss: 0.6506 \n",
      "\n",
      "Epoch [334/334], Step [7/7], d_loss: 10.0536, g_loss: 0.6532 \n",
      "\n",
      "Epoch [335/335], Step [7/7], d_loss: 10.9701, g_loss: 0.6543 \n",
      "\n",
      "Epoch [336/336], Step [7/7], d_loss: 16.2101, g_loss: 0.6525 \n",
      "\n",
      "Epoch [337/337], Step [7/7], d_loss: 29.8099, g_loss: 0.6541 \n",
      "\n",
      "Epoch [338/338], Step [7/7], d_loss: 26.7460, g_loss: 0.6533 \n",
      "\n",
      "Epoch [339/339], Step [7/7], d_loss: 21.3573, g_loss: 0.6522 \n",
      "\n",
      "Epoch [340/340], Step [7/7], d_loss: 27.1826, g_loss: 0.6525 \n",
      "\n",
      "Epoch [341/341], Step [7/7], d_loss: 17.7877, g_loss: 0.6529 \n",
      "\n",
      "Epoch [342/342], Step [7/7], d_loss: 10.7517, g_loss: 0.6515 \n",
      "\n",
      "Epoch [343/343], Step [7/7], d_loss: 9.8969, g_loss: 0.6511 \n",
      "\n",
      "Epoch [344/344], Step [7/7], d_loss: 10.7442, g_loss: 0.6536 \n",
      "\n",
      "Epoch [345/345], Step [7/7], d_loss: 9.8562, g_loss: 0.6495 \n",
      "\n",
      "Epoch [346/346], Step [7/7], d_loss: 18.7407, g_loss: 0.6536 \n",
      "\n",
      "Epoch [347/347], Step [7/7], d_loss: 40.8787, g_loss: 0.6519 \n",
      "\n",
      "Epoch [348/348], Step [7/7], d_loss: 17.9096, g_loss: 0.6530 \n",
      "\n",
      "Epoch [349/349], Step [7/7], d_loss: 17.8781, g_loss: 0.6485 \n",
      "\n",
      "Epoch [350/350], Step [7/7], d_loss: 26.7467, g_loss: 0.6535 \n",
      "\n",
      "Epoch [351/351], Step [7/7], d_loss: 18.7450, g_loss: 0.6517 \n",
      "\n",
      "Epoch [352/352], Step [7/7], d_loss: 27.0944, g_loss: 0.6532 \n",
      "\n",
      "Epoch [353/353], Step [7/7], d_loss: 9.8903, g_loss: 0.6518 \n",
      "\n",
      "Epoch [354/354], Step [7/7], d_loss: 25.8049, g_loss: 0.6513 \n",
      "\n",
      "Epoch [355/355], Step [7/7], d_loss: 26.7412, g_loss: 0.6525 \n",
      "\n",
      "Epoch [356/356], Step [7/7], d_loss: 26.7454, g_loss: 0.6530 \n",
      "\n",
      "Epoch [357/357], Step [7/7], d_loss: 14.8673, g_loss: 0.6515 \n",
      "\n",
      "Epoch [358/358], Step [7/7], d_loss: 10.7432, g_loss: 0.6515 \n",
      "\n",
      "Epoch [359/359], Step [7/7], d_loss: 9.8915, g_loss: 0.6515 \n",
      "\n",
      "Epoch [360/360], Step [7/7], d_loss: 30.4291, g_loss: 0.6532 \n",
      "\n",
      "Epoch [361/361], Step [7/7], d_loss: 18.8810, g_loss: 0.6521 \n",
      "\n",
      "Epoch [362/362], Step [7/7], d_loss: 10.7460, g_loss: 0.6534 \n",
      "\n",
      "Epoch [363/363], Step [7/7], d_loss: 17.8784, g_loss: 0.6526 \n",
      "\n",
      "Epoch [364/364], Step [7/7], d_loss: 15.6056, g_loss: 0.6526 \n",
      "\n",
      "Epoch [365/365], Step [7/7], d_loss: 10.7448, g_loss: 0.6521 \n",
      "\n",
      "Epoch [366/366], Step [7/7], d_loss: 13.7271, g_loss: 0.6509 \n",
      "\n",
      "Epoch [367/367], Step [7/7], d_loss: 18.7451, g_loss: 0.6525 \n",
      "\n",
      "Epoch [368/368], Step [7/7], d_loss: 17.4993, g_loss: 0.6517 \n",
      "\n",
      "Epoch [369/369], Step [7/7], d_loss: 14.0701, g_loss: 0.6517 \n",
      "\n",
      "Epoch [370/370], Step [7/7], d_loss: 12.2881, g_loss: 0.6517 \n",
      "\n",
      "Epoch [371/371], Step [7/7], d_loss: 18.1483, g_loss: 0.6522 \n",
      "\n",
      "Epoch [372/372], Step [7/7], d_loss: 18.7496, g_loss: 0.6529 \n",
      "\n",
      "Epoch [373/373], Step [7/7], d_loss: 27.0467, g_loss: 0.6501 \n",
      "\n",
      "Epoch [374/374], Step [7/7], d_loss: 27.4225, g_loss: 0.6521 \n",
      "\n",
      "Epoch [375/375], Step [7/7], d_loss: 18.7407, g_loss: 0.6502 \n",
      "\n",
      "Epoch [376/376], Step [7/7], d_loss: 18.7473, g_loss: 0.6516 \n",
      "\n",
      "Epoch [377/377], Step [7/7], d_loss: 19.1279, g_loss: 0.6520 \n",
      "\n",
      "Epoch [378/378], Step [7/7], d_loss: 14.6738, g_loss: 0.6521 \n",
      "\n",
      "Epoch [379/379], Step [7/7], d_loss: 25.3012, g_loss: 0.6525 \n",
      "\n",
      "Epoch [380/380], Step [7/7], d_loss: 18.6167, g_loss: 0.6523 \n",
      "\n",
      "Epoch [381/381], Step [7/7], d_loss: 16.0530, g_loss: 0.6525 \n",
      "\n",
      "Epoch [382/382], Step [7/7], d_loss: 16.7671, g_loss: 0.6529 \n",
      "\n",
      "Epoch [383/383], Step [7/7], d_loss: 13.7551, g_loss: 0.6519 \n",
      "\n",
      "Epoch [384/384], Step [7/7], d_loss: 19.5646, g_loss: 0.6522 \n",
      "\n",
      "Epoch [385/385], Step [7/7], d_loss: 14.6082, g_loss: 0.6531 \n",
      "\n",
      "Epoch [386/386], Step [7/7], d_loss: 10.7462, g_loss: 0.6528 \n",
      "\n",
      "Epoch [387/387], Step [7/7], d_loss: 18.7476, g_loss: 0.6521 \n",
      "\n",
      "Epoch [388/388], Step [7/7], d_loss: 18.7475, g_loss: 0.6531 \n",
      "\n",
      "Epoch [389/389], Step [7/7], d_loss: 20.2855, g_loss: 0.6518 \n",
      "\n",
      "Epoch [390/390], Step [7/7], d_loss: 13.4536, g_loss: 0.6525 \n",
      "\n",
      "Epoch [391/391], Step [7/7], d_loss: 24.4639, g_loss: 0.6532 \n",
      "\n",
      "Epoch [392/392], Step [7/7], d_loss: 10.7479, g_loss: 0.6528 \n",
      "\n",
      "Epoch [393/393], Step [7/7], d_loss: 28.9209, g_loss: 0.6530 \n",
      "\n",
      "Epoch [394/394], Step [7/7], d_loss: 15.7248, g_loss: 0.6512 \n",
      "\n",
      "Epoch [395/395], Step [7/7], d_loss: 18.9611, g_loss: 0.6538 \n",
      "\n",
      "Epoch [396/396], Step [7/7], d_loss: 14.7185, g_loss: 0.6517 \n",
      "\n",
      "Epoch [397/397], Step [7/7], d_loss: 23.1976, g_loss: 0.6524 \n",
      "\n",
      "Epoch [398/398], Step [7/7], d_loss: 23.6402, g_loss: 0.6481 \n",
      "\n",
      "Epoch [399/399], Step [7/7], d_loss: 17.8383, g_loss: 0.6520 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_gen, losses_dis = gan.train(df_train, 64, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(losses_gen, losses_dis):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "\n",
    "    #convert losses into numpy\n",
    "    losses_gen = [i.detach().numpy() for i in losses_gen]\n",
    "    losses_dis = [i.detach().numpy() for i in losses_dis]\n",
    "    plt.plot(losses_gen,label=\"Generator\")\n",
    "    plt.plot(losses_dis,label=\"Discriminator\")\n",
    "    plt.xlabel(\"iterations\") #Epochs * Steps\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(losses_gen, losses_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[846], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_number \u001b[38;5;241m=\u001b[39m df_train[df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m gan_samples \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m samples_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(gan_samples, np\u001b[38;5;241m.\u001b[39mones((sample_number, \u001b[38;5;241m1\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m gan_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(samples_test, columns\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "Cell \u001b[0;32mIn[842], line 56\u001b[0m, in \u001b[0;36mGAN.sample\u001b[0;34m(self, count)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     55\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (count, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_size)))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 56\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[834], line 36\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 36\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msigmoid(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_number = df_train[df_train['Class'] == 0].shape[0]\n",
    "gan_samples = gan.sample(sample_number)\n",
    "samples_test = np.append(gan_samples, np.ones((sample_number, 1)), axis=1)\n",
    "gan_df = pd.DataFrame(samples_test, columns=df_train.columns)\n",
    "#concat wgan_df with df_train\n",
    "df_concat = pd.concat([df_train, gan_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223361</th>\n",
       "      <td>143352.0</td>\n",
       "      <td>1.955041</td>\n",
       "      <td>-0.380783</td>\n",
       "      <td>-0.315013</td>\n",
       "      <td>0.330155</td>\n",
       "      <td>-0.509374</td>\n",
       "      <td>-0.086197</td>\n",
       "      <td>-0.627978</td>\n",
       "      <td>0.035994</td>\n",
       "      <td>1.054560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238197</td>\n",
       "      <td>0.968305</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>-0.278602</td>\n",
       "      <td>-0.044999</td>\n",
       "      <td>-0.216780</td>\n",
       "      <td>0.045168</td>\n",
       "      <td>-0.047145</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165061</th>\n",
       "      <td>117173.0</td>\n",
       "      <td>-0.400975</td>\n",
       "      <td>-0.626943</td>\n",
       "      <td>1.555339</td>\n",
       "      <td>-2.017772</td>\n",
       "      <td>-0.107769</td>\n",
       "      <td>0.168310</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>-0.401619</td>\n",
       "      <td>0.040378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153485</td>\n",
       "      <td>0.421703</td>\n",
       "      <td>0.113442</td>\n",
       "      <td>-1.004095</td>\n",
       "      <td>-1.176695</td>\n",
       "      <td>0.361924</td>\n",
       "      <td>-0.370469</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>45.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238186</th>\n",
       "      <td>149565.0</td>\n",
       "      <td>0.072509</td>\n",
       "      <td>0.820566</td>\n",
       "      <td>-0.561351</td>\n",
       "      <td>-0.709897</td>\n",
       "      <td>1.080399</td>\n",
       "      <td>-0.359429</td>\n",
       "      <td>0.787858</td>\n",
       "      <td>0.117276</td>\n",
       "      <td>-0.131275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314638</td>\n",
       "      <td>-0.872959</td>\n",
       "      <td>0.083391</td>\n",
       "      <td>0.148178</td>\n",
       "      <td>-0.431459</td>\n",
       "      <td>0.119690</td>\n",
       "      <td>0.206395</td>\n",
       "      <td>0.070288</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150562</th>\n",
       "      <td>93670.0</td>\n",
       "      <td>-0.535045</td>\n",
       "      <td>1.014587</td>\n",
       "      <td>1.750679</td>\n",
       "      <td>2.769390</td>\n",
       "      <td>0.500089</td>\n",
       "      <td>1.002270</td>\n",
       "      <td>0.847902</td>\n",
       "      <td>-0.081323</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063525</td>\n",
       "      <td>0.443431</td>\n",
       "      <td>-0.072754</td>\n",
       "      <td>0.448192</td>\n",
       "      <td>-0.655203</td>\n",
       "      <td>-0.181038</td>\n",
       "      <td>-0.093013</td>\n",
       "      <td>-0.064931</td>\n",
       "      <td>117.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138452</th>\n",
       "      <td>82655.0</td>\n",
       "      <td>-4.026938</td>\n",
       "      <td>1.897371</td>\n",
       "      <td>-0.429786</td>\n",
       "      <td>-0.029571</td>\n",
       "      <td>-0.855751</td>\n",
       "      <td>-0.480406</td>\n",
       "      <td>-0.435632</td>\n",
       "      <td>1.313760</td>\n",
       "      <td>0.536044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.480691</td>\n",
       "      <td>-0.230369</td>\n",
       "      <td>0.250717</td>\n",
       "      <td>0.066399</td>\n",
       "      <td>0.470787</td>\n",
       "      <td>0.245335</td>\n",
       "      <td>0.286904</td>\n",
       "      <td>-0.322672</td>\n",
       "      <td>25.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "223361  143352.0  1.955041 -0.380783 -0.315013  0.330155 -0.509374 -0.086197   \n",
       "165061  117173.0 -0.400975 -0.626943  1.555339 -2.017772 -0.107769  0.168310   \n",
       "238186  149565.0  0.072509  0.820566 -0.561351 -0.709897  1.080399 -0.359429   \n",
       "150562   93670.0 -0.535045  1.014587  1.750679  2.769390  0.500089  1.002270   \n",
       "138452   82655.0 -4.026938  1.897371 -0.429786 -0.029571 -0.855751 -0.480406   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "223361 -0.627978  0.035994  1.054560  ...  0.238197  0.968305  0.053208   \n",
       "165061  0.017959 -0.401619  0.040378  ... -0.153485  0.421703  0.113442   \n",
       "238186  0.787858  0.117276 -0.131275  ... -0.314638 -0.872959  0.083391   \n",
       "150562  0.847902 -0.081323  0.371579  ...  0.063525  0.443431 -0.072754   \n",
       "138452 -0.435632  1.313760  0.536044  ... -0.480691 -0.230369  0.250717   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "223361 -0.278602 -0.044999 -0.216780  0.045168 -0.047145    9.99      0  \n",
       "165061 -1.004095 -1.176695  0.361924 -0.370469 -0.144792   45.90      0  \n",
       "238186  0.148178 -0.431459  0.119690  0.206395  0.070288   11.99      0  \n",
       "150562  0.448192 -0.655203 -0.181038 -0.093013 -0.064931  117.44      0  \n",
       "138452  0.066399  0.470787  0.245335  0.286904 -0.322672   25.76      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491395</td>\n",
       "      <td>0.562342</td>\n",
       "      <td>0.506892</td>\n",
       "      <td>0.547977</td>\n",
       "      <td>0.476935</td>\n",
       "      <td>0.472317</td>\n",
       "      <td>0.472835</td>\n",
       "      <td>0.536043</td>\n",
       "      <td>0.540486</td>\n",
       "      <td>0.501665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498170</td>\n",
       "      <td>0.442935</td>\n",
       "      <td>0.574136</td>\n",
       "      <td>0.454098</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.522551</td>\n",
       "      <td>0.536547</td>\n",
       "      <td>0.541110</td>\n",
       "      <td>0.565920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481106</td>\n",
       "      <td>0.554959</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.552758</td>\n",
       "      <td>0.472596</td>\n",
       "      <td>0.483215</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.538077</td>\n",
       "      <td>0.527347</td>\n",
       "      <td>0.510621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504254</td>\n",
       "      <td>0.432635</td>\n",
       "      <td>0.569126</td>\n",
       "      <td>0.450525</td>\n",
       "      <td>0.547658</td>\n",
       "      <td>0.526130</td>\n",
       "      <td>0.534143</td>\n",
       "      <td>0.539301</td>\n",
       "      <td>0.558317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488733</td>\n",
       "      <td>0.548983</td>\n",
       "      <td>0.510994</td>\n",
       "      <td>0.546946</td>\n",
       "      <td>0.485065</td>\n",
       "      <td>0.470796</td>\n",
       "      <td>0.486048</td>\n",
       "      <td>0.522694</td>\n",
       "      <td>0.547030</td>\n",
       "      <td>0.486649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>0.458859</td>\n",
       "      <td>0.563332</td>\n",
       "      <td>0.461384</td>\n",
       "      <td>0.549788</td>\n",
       "      <td>0.523642</td>\n",
       "      <td>0.546768</td>\n",
       "      <td>0.540727</td>\n",
       "      <td>0.557351</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487719</td>\n",
       "      <td>0.560852</td>\n",
       "      <td>0.501906</td>\n",
       "      <td>0.546891</td>\n",
       "      <td>0.472037</td>\n",
       "      <td>0.476458</td>\n",
       "      <td>0.473072</td>\n",
       "      <td>0.540346</td>\n",
       "      <td>0.539275</td>\n",
       "      <td>0.506550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497857</td>\n",
       "      <td>0.439769</td>\n",
       "      <td>0.577819</td>\n",
       "      <td>0.451887</td>\n",
       "      <td>0.544660</td>\n",
       "      <td>0.521305</td>\n",
       "      <td>0.538590</td>\n",
       "      <td>0.537846</td>\n",
       "      <td>0.562290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481222</td>\n",
       "      <td>0.569424</td>\n",
       "      <td>0.509925</td>\n",
       "      <td>0.555719</td>\n",
       "      <td>0.483539</td>\n",
       "      <td>0.468364</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>0.540777</td>\n",
       "      <td>0.541175</td>\n",
       "      <td>0.513675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507181</td>\n",
       "      <td>0.432278</td>\n",
       "      <td>0.569952</td>\n",
       "      <td>0.443107</td>\n",
       "      <td>0.533884</td>\n",
       "      <td>0.512438</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.535235</td>\n",
       "      <td>0.562844</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227446</th>\n",
       "      <td>0.479325</td>\n",
       "      <td>0.561050</td>\n",
       "      <td>0.511826</td>\n",
       "      <td>0.551025</td>\n",
       "      <td>0.486390</td>\n",
       "      <td>0.459871</td>\n",
       "      <td>0.465834</td>\n",
       "      <td>0.546472</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>0.517431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511376</td>\n",
       "      <td>0.441019</td>\n",
       "      <td>0.558068</td>\n",
       "      <td>0.434781</td>\n",
       "      <td>0.534068</td>\n",
       "      <td>0.501633</td>\n",
       "      <td>0.532107</td>\n",
       "      <td>0.537337</td>\n",
       "      <td>0.549987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227447</th>\n",
       "      <td>0.472108</td>\n",
       "      <td>0.557288</td>\n",
       "      <td>0.512165</td>\n",
       "      <td>0.559487</td>\n",
       "      <td>0.483674</td>\n",
       "      <td>0.477920</td>\n",
       "      <td>0.476903</td>\n",
       "      <td>0.536755</td>\n",
       "      <td>0.534263</td>\n",
       "      <td>0.514812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512362</td>\n",
       "      <td>0.428061</td>\n",
       "      <td>0.566157</td>\n",
       "      <td>0.445227</td>\n",
       "      <td>0.546085</td>\n",
       "      <td>0.519266</td>\n",
       "      <td>0.533541</td>\n",
       "      <td>0.531409</td>\n",
       "      <td>0.552739</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227448</th>\n",
       "      <td>0.485168</td>\n",
       "      <td>0.564543</td>\n",
       "      <td>0.506326</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>0.473840</td>\n",
       "      <td>0.535895</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502029</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.579781</td>\n",
       "      <td>0.453785</td>\n",
       "      <td>0.538554</td>\n",
       "      <td>0.518806</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.536735</td>\n",
       "      <td>0.570644</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227449</th>\n",
       "      <td>0.475617</td>\n",
       "      <td>0.552065</td>\n",
       "      <td>0.510140</td>\n",
       "      <td>0.553162</td>\n",
       "      <td>0.473518</td>\n",
       "      <td>0.483321</td>\n",
       "      <td>0.476756</td>\n",
       "      <td>0.536845</td>\n",
       "      <td>0.532475</td>\n",
       "      <td>0.506071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503477</td>\n",
       "      <td>0.432074</td>\n",
       "      <td>0.567214</td>\n",
       "      <td>0.449680</td>\n",
       "      <td>0.546944</td>\n",
       "      <td>0.524494</td>\n",
       "      <td>0.532451</td>\n",
       "      <td>0.537795</td>\n",
       "      <td>0.555340</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227450</th>\n",
       "      <td>0.484246</td>\n",
       "      <td>0.559164</td>\n",
       "      <td>0.511024</td>\n",
       "      <td>0.550191</td>\n",
       "      <td>0.487622</td>\n",
       "      <td>0.455416</td>\n",
       "      <td>0.465919</td>\n",
       "      <td>0.547732</td>\n",
       "      <td>0.553459</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515438</td>\n",
       "      <td>0.437771</td>\n",
       "      <td>0.562706</td>\n",
       "      <td>0.436489</td>\n",
       "      <td>0.529717</td>\n",
       "      <td>0.506666</td>\n",
       "      <td>0.534283</td>\n",
       "      <td>0.538601</td>\n",
       "      <td>0.551865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227451 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0.491395  0.562342  0.506892  0.547977  0.476935  0.472317  0.472835   \n",
       "1       0.481106  0.554959  0.513611  0.552758  0.472596  0.483215  0.471799   \n",
       "2       0.488733  0.548983  0.510994  0.546946  0.485065  0.470796  0.486048   \n",
       "3       0.487719  0.560852  0.501906  0.546891  0.472037  0.476458  0.473072   \n",
       "4       0.481222  0.569424  0.509925  0.555719  0.483539  0.468364  0.468320   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "227446  0.479325  0.561050  0.511826  0.551025  0.486390  0.459871  0.465834   \n",
       "227447  0.472108  0.557288  0.512165  0.559487  0.483674  0.477920  0.476903   \n",
       "227448  0.485168  0.564543  0.506326  0.543763  0.471375  0.469592  0.473840   \n",
       "227449  0.475617  0.552065  0.510140  0.553162  0.473518  0.483321  0.476756   \n",
       "227450  0.484246  0.559164  0.511024  0.550191  0.487622  0.455416  0.465919   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0       0.536043  0.540486  0.501665  ...  0.498170  0.442935  0.574136   \n",
       "1       0.538077  0.527347  0.510621  ...  0.504254  0.432635  0.569126   \n",
       "2       0.522694  0.547030  0.486649  ...  0.499048  0.458859  0.563332   \n",
       "3       0.540346  0.539275  0.506550  ...  0.497857  0.439769  0.577819   \n",
       "4       0.540777  0.541175  0.513675  ...  0.507181  0.432278  0.569952   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "227446  0.546472  0.554041  0.517431  ...  0.511376  0.441019  0.558068   \n",
       "227447  0.536755  0.534263  0.514812  ...  0.512362  0.428061  0.566157   \n",
       "227448  0.535895  0.538390  0.499695  ...  0.502029  0.444244  0.579781   \n",
       "227449  0.536845  0.532475  0.506071  ...  0.503477  0.432074  0.567214   \n",
       "227450  0.547732  0.553459  0.519005  ...  0.515438  0.437771  0.562706   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "0       0.454098  0.540230  0.522551  0.536547  0.541110  0.565920    1.0  \n",
       "1       0.450525  0.547658  0.526130  0.534143  0.539301  0.558317    1.0  \n",
       "2       0.461384  0.549788  0.523642  0.546768  0.540727  0.557351    1.0  \n",
       "3       0.451887  0.544660  0.521305  0.538590  0.537846  0.562290    1.0  \n",
       "4       0.443107  0.533884  0.512438  0.528025  0.535235  0.562844    1.0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "227446  0.434781  0.534068  0.501633  0.532107  0.537337  0.549987    1.0  \n",
       "227447  0.445227  0.546085  0.519266  0.533541  0.531409  0.552739    1.0  \n",
       "227448  0.453785  0.538554  0.518806  0.539256  0.536735  0.570644    1.0  \n",
       "227449  0.449680  0.546944  0.524494  0.532451  0.537795  0.555340    1.0  \n",
       "227450  0.436489  0.529717  0.506666  0.534283  0.538601  0.551865    1.0  \n",
       "\n",
       "[227451 rows x 31 columns]"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1.0    227845\n",
       "0.0    227451\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, nr_features):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(nr_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudModel:\n",
    "    def __init__(self, train_df):\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 64\n",
    "        self.dataset = FraudDataset(train_df, fraud = False)\n",
    "        self.dataloader = DataLoader(self.dataset, self.batch_size, shuffle=True)\n",
    "        self.model = Model(nr_features=self.dataset.features).to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "    def train(self, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for _, (x, y) in enumerate(self.dataloader):\n",
    "                self.optimizer.zero_grad()\n",
    "                y_pred = self.model(x)\n",
    "                loss = self.loss(y_pred, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item() / len(x)\n",
    "            print(\"[Epoch %d/%d] loss: %f\" % (epoch, epochs, np.mean(epoch_loss)))\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(x)\n",
    "            return pred.cpu().numpy()\n",
    "        \n",
    "    def evaluate(self, test_df, confidence=0.50):\n",
    "        input = torch.Tensor(test_df.drop(['Class'], axis=1).values).to(device)\n",
    "        preds = self.predict(input)\n",
    "        labels = np.zeros_like(preds)\n",
    "        labels[preds >= confidence] = 1\n",
    "        ConfusionMatrixDisplay.from_predictions(test_df['Class'].values, labels, normalize='true')\n",
    "        print(classification_report(test_df['Class'].values, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[828], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fw_model \u001b[38;5;241m=\u001b[39m FraudModel(df_concat)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfw_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m fw_model\u001b[38;5;241m.\u001b[39mevaluate(df_test, confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m)\n",
      "Cell \u001b[0;32mIn[827], line 16\u001b[0m, in \u001b[0;36mFraudModel.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(y_pred, y)\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[826], line 19\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fw_model = FraudModel(df_concat)\n",
    "fw_model.train(epochs=100)\n",
    "fw_model.evaluate(df_test, confidence=0.90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
